{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8eca5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#no need to refresh kernel when changes are made to the helper scripts\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354864c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a9b40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from IPython.display import display,FileLink, Markdown, HTML, Image\n",
    "\n",
    "cwd = os.path.dirname(os.getcwd()) #add the cwd so that python scripts can be imported.\n",
    "if cwd not in sys.path:\n",
    "    sys.path.insert(0, cwd)\n",
    "\n",
    "#to save in the same directory as the notebook, change to resource_path=\"\".\n",
    "\n",
    "# print(project_root)\n",
    "# print(resource_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9608ac7e",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#parameters\n",
    "gse = \"GSE247175\"\n",
    "project_root = cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65c3cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "resource_path = os.path.join(project_root, \"output\", gse)\n",
    "Path(resource_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946e9a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def suppress_output(stdout=True, stderr=True, dest='/dev/null'):\n",
    "    ''' Usage:\n",
    "    with suppress_output():\n",
    "        print('hi')\n",
    "    '''\n",
    "    dev_null = open(dest, 'a')\n",
    "    if stdout:\n",
    "        _stdout = sys.stdout\n",
    "        sys.stdout = dev_null\n",
    "    if stderr:\n",
    "        _stderr = sys.stderr\n",
    "        sys.stderr = dev_null\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        if stdout:\n",
    "            sys.stdout = _stdout\n",
    "        if stderr:\n",
    "            sys.stderr = _stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75f0483",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['ENTREZ_EMAIL'] = os.getenv('ENTREZ_EMAIL')\n",
    "\n",
    "Entrez.email = os.environ['ENTREZ_EMAIL']\n",
    "\n",
    "id_handle = Entrez.esearch(db=\"gds\", term=f\"{gse}[Accession]\", retmax=1)\n",
    "id_record = Entrez.read(id_handle)\n",
    "gds_id = id_record[\"IdList\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf63e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = Entrez.esummary(db='gds', id=gds_id)\n",
    "record = Entrez.read(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e6e96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_species = {\n",
    "    \"homo sapiens\": \"human\",\n",
    "    \"mus musculus\": \"mouse\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44949fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "species = map_species[record[0]['taxon'].lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9738088",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(record[0]['PubMedIds'])==0: #discard studies with no pubmed citation\n",
    "    raise ValueError(\"No PubMed citation found for this study.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f934bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmid = int(record[0]['PubMedIds'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b1f071",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(record[0]['Samples']) not in range(6, 25): #discard studies that dont have 6-24 samples\n",
    "    raise ValueError(\"Number of samples need to be within 6-24.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98ce279",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_pubmed_metadata(pmid):\n",
    "    handle = Entrez.efetch(db=\"pubmed\", id=pmid, retmode=\"xml\")\n",
    "    records = Entrez.read(handle)\n",
    "    article = records['PubmedArticle'][0]['MedlineCitation']['Article']\n",
    "\n",
    "    title = article['ArticleTitle']\n",
    "    journal = article['Journal']['Title']\n",
    "    journal_abbr = article['Journal']['ISOAbbreviation']\n",
    "    year = article['Journal']['JournalIssue']['PubDate'].get('Year', '')\n",
    "    volume = article['Journal']['JournalIssue'].get('Volume', '')\n",
    "    issue = article['Journal']['JournalIssue'].get('Issue', '')\n",
    "    pages = article.get('Pagination', {}).get('MedlinePgn', '')\n",
    "    authors = article.get('AuthorList', [])\n",
    "\n",
    "    # def format_author(author):\n",
    "    #     initials = ''.join(author.get('Initials', ''))\n",
    "    #     return f\"{author['LastName']} {initials}\"\n",
    "\n",
    "    def format_author(author):\n",
    "        initials = '. '.join(author.get('Initials', '')) + '.'\n",
    "        return f\"{author['LastName']}, {initials}\"\n",
    "\n",
    "\n",
    "    authors = [format_author(a) for a in authors]\n",
    "\n",
    "    return {\n",
    "        \"title\": title,\n",
    "        \"journal\": journal,\n",
    "        \"year\": year,\n",
    "        \"volume\": volume,\n",
    "        \"issue\": issue,\n",
    "        \"pages\": pages,\n",
    "        \"authors\": authors\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1876f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmdict = fetch_pubmed_metadata(pmid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b00ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_apa_citation(metadata, pmid=None):\n",
    "    authors = metadata['authors']\n",
    "\n",
    "    if len(authors) <= 20:\n",
    "        if len(authors) > 1:\n",
    "            author_str = ', '.join(authors[:-1]) + ', & ' + authors[-1]\n",
    "        else:\n",
    "            author_str = authors[0]\n",
    "    else:\n",
    "        author_str = ', '.join(authors[:19]) + ', ... ' + authors[-1]\n",
    "\n",
    "    citation = (\n",
    "        f\"{author_str} ({metadata['year']}). {metadata['title']} \"\n",
    "        f\"*{metadata['journal']}*, {metadata['volume']}({metadata['issue']}), {metadata['pages']}.\"\n",
    "    )\n",
    "\n",
    "    if metadata.get('doi'):\n",
    "        citation += f\" https://doi.org/{metadata['doi']}\"\n",
    "    elif pmid:\n",
    "        citation += f\" PMID: {pmid}\"\n",
    "\n",
    "    return citation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5985ff11",
   "metadata": {},
   "outputs": [],
   "source": [
    "citation = format_apa_citation(pmdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79709767",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f\"# **Reanalysis of \\\"{pmdict['title']}\\\" by {pmdict['authors'][0]} et al., {pmdict['journal']}, {pmdict['year']}**\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796adb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "link = f\"https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc={gse}\"\n",
    "display(Markdown(f\"{citation}\"))\n",
    "HTML(f'<a href=\"{link}\" target=\"_blank\">Visit GEO accession page</a>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7579908",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "client = genai.Client(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "#print(os.environ[\"GOOGLE_API_KEY\"])\n",
    "prompt = f'''\n",
    "  You are an expert academic writer. Your task is to reformat the provided research information into a concise abstract around 250 words following this exact template:\n",
    "\n",
    "  \"In this study, <FIRST AUTHOR> et al. [1] profiled <CELLS AND CONDITIONS> to further our understanding of <TOPIC>. The reanalysis of this dataset include <FILL IN>\"\n",
    "\n",
    "  Here is the contextual information:\n",
    "  Author: {pmdict['authors']}\n",
    "  Title: {pmdict['title']}\n",
    "  Summary: {record[0]['summary']}\n",
    "\n",
    "  In the reanalysis explanation, use the following information: the reanalysis is a full RNA-seq analysis pipeline that consists of: UMAP[2], PCA[3], t-SNE[4] plots of the samples; clustergram heatmap; differential gene expression analysis\n",
    "  for each pair of control and perturbation samples; Enrichment analysis for each gene signature using Enrichr [5, 6, 7]; Transcription factor analysis of gene signatures\n",
    "  using ChEA3 [8] ; Reverser and mimicker drug match analysis using L2S2 [9] and DRUG-seqr [10], both FDA and non-FDA approved. Results are provided as tables in addition to bar charts.\n",
    "\n",
    "  Please write the reanalysis as a complete paragraph with smoothly transitioning sentences. Use consistent, present tense.\n",
    "  Do not omit or change the ordering of the reference numbers.\n",
    "  Do not change the reference and insert it, in parentheses, where indicated. \n",
    "\n",
    "  Now, generate the abstract strictly following the template. Do not include any other text or introductory/concluding remarks.\n",
    "'''\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\", contents=prompt\n",
    ")\n",
    "#print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab7b2b0",
   "metadata": {},
   "source": [
    "## **Abstract**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9094c5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f\"{response.text}\\n*This abstract was generated with the assistance of Gemini 2.0 Flash.*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1091ef8",
   "metadata": {},
   "source": [
    "## **Methods**\n",
    "\n",
    "*RNA-seq alignment*\n",
    "\n",
    "Gene count matrices were obtained from ARCHS4 [11], which preprocessed the raw FASTQ data using the Kallisto [12] and STAR [] pseudoalignment algorithm.\n",
    "\n",
    "*Gene matrix processing* \n",
    "\n",
    "The raw gene matrix was filtered to remove genes that do not have an average of 3 reads across the samples. It was then quantile, log2, and z-score normalized. A regex-based function was used to infer whether individual samples belong to a “control” or a “perturbation” group by processing the metadata associated with each sample. \n",
    "\n",
    "*Dimensionality Reduction Visualization*\n",
    "\n",
    "Three types of dimensionality reduction techniques were applied on the processed expression matrices: UMAP[2], PCA[3], and t-SNE[4]. UMAP was calculated by the UMAP Python package and PCA and t-SNE were calculated using the Scikit-Learn Python library. The samples were then represented on 2D scatterplots.\n",
    "\n",
    "*Clustergram Heatmap*\n",
    "\n",
    "As a preliminary step, the top 1000 genes exhibiting most variability were selected. Using this new set, clustergram heatmaps were generated. Two versions of the clustergram exist: an interactive one generated by Clustergrammer [13] and a publication-ready alternative.\n",
    "\n",
    "*Differentially Expressed Genes Calculation and Volcano Plot*\n",
    "\n",
    "Differentially expressed genes between the control and perturbation samples were calculated using Limma Voom [14]. The logFC and -log10p values of each gene were visualized as a volcano scatterplot. Upregulated and downregulated genes were selected according to this criteria: p < 0.05 and |logFC| > 1.0.\n",
    "\n",
    "*Enrichr Enrichment Analysis*\n",
    "\n",
    "The upregulated and down-regulated sets were separately submitted to Enrichr [5, 6, 7]. These sets were compared against libraries from ChEA [8], ARCHS4 [12], Reactome Pathways [15], MGI Mammalian Phenotype [16], Gene Ontology Biological Processes [17], GWAS Catalog [18], KEGG [19, 20, 21], and WikiPathways [22]. The top matched terms from each library and their respective -log10p values were visualized as barplots.\n",
    "\n",
    "*Chea3 Transcription Factor Analysis*\n",
    "\n",
    "The upregulated and down-regulated sets were separately submitted to Chea3 [8]. These sets were compared against the libraries ARCHS4 Coexpression [12], GTEx Coexpression [23], Enrichr [5, 6, 7], ENCODE ChIP-seq [24, 25], ReMap ChIP-seq [26], and Literature-mined ChIP-seq. The top matched TFs were ranked according to their average score across each library and represented as barplots.\n",
    "\n",
    "*L2S2 and Drug-seqr drug analysis*\n",
    "\n",
    "The top 500 up and downregulated sets were submitted simulataneously to identify reverser and mimicker molecules, both FDA and non-FDA approved, from the L2S2 [9] and Drug-seqr [10] databases. The top matched molecules were compiled into tables and visualized as barplots. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5f160b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "#write a json file as a catalog list.\n",
    "metadata_path = Path(os.path.join(project_root, \"public\", \"metadata.json\"))\n",
    "\n",
    "# 1. Load existing metadata (or create empty if file doesn't exist)\n",
    "if metadata_path.exists():\n",
    "    with open(metadata_path, \"r\") as f:\n",
    "        metadata = json.load(f)\n",
    "else:\n",
    "    metadata = {}\n",
    "\n",
    "\n",
    "entry = {\n",
    "    \"id\": gse, \n",
    "    \"author\": \", \".join(pmdict['authors']),\n",
    "    \"year\": int(pmdict['year']),\n",
    "    \"species\": species,\n",
    "    \"title\": pmdict['title'],\n",
    "    \"pmid\": pmid,\n",
    "    \"num_samps\": len(record[0]['Samples']),\n",
    "    \"samples\": \", \".join(sorted([w['Accession'] for w in record[0]['Samples']])),\n",
    "    \"citation\": citation,\n",
    "    #\"notebook_path\": f\"{resource_path}/{gse}.ipynb\",\n",
    "    #\"report_path\": f\"{resource_path}/{gse}.html\",\n",
    "    \"timestamp\": datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "# 3. Add entry only if it doesn't already exist\n",
    "if gse not in metadata:\n",
    "    metadata[gse] = entry\n",
    "    print(f\"[INFO] Added metadata for {gse}\")\n",
    "else:\n",
    "    print(f\"[INFO] {gse} already exists in metadata. Skipping update.\")\n",
    "\n",
    "# 4. Write updated metadata back to file\n",
    "with open(metadata_path, \"w\") as f:\n",
    "    json.dump(metadata, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d115ce0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_num = 1\n",
    "fig_num = 1\n",
    "save_formats = ['png', 'svg', 'jpeg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d05682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import archs4py as a4\n",
    "#file_path = a4.download.counts(\"human\", path=\"\", version=\"latest\") #comment out if the file is already downloaded\n",
    "file = os.path.join(\"/home/ajy20/projects/8--auto-playbook-geo-reports\", \"human_gene_v2.latest.h5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f101e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = a4.meta.series(file, gse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4326791",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "words_to_remove = ['experiement', 'tissue', 'type', 'batch', 'treatment', 'experiment', 'patient', 'batch', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "stopwords_plus = set(stopwords.words('english') + (words_to_remove))\n",
    "pattern = r'[-,_.:]'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e380c238",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_to_remove = [\"cell line\", \"cell type\", \"genotype\", \"treatment\"]\n",
    "\n",
    "\n",
    "pattern1 = r\"\\b(\" + \"|\".join(map(re.escape, terms_to_remove)) + r\")\\b\"\n",
    "\n",
    "metadata[\"cleaned_characteristics\"] = metadata[\"characteristics_ch1\"].str.replace(\n",
    "    pattern1, \n",
    "    \"\", \n",
    "    flags=re.IGNORECASE, \n",
    "    regex=True\n",
    ").str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "\n",
    "metadata['cleaned_characteristics'] = metadata['cleaned_characteristics'].apply(lambda x: re.sub(pattern, \" \", x).strip().lower())\n",
    "metadata['cleaned_characteristics'] = metadata['cleaned_characteristics'].apply(\n",
    "    lambda text: \" \".join([word for word in text.split() if word not in stopwords_plus])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c78e306",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['clean_title'] = metadata['title'].apply(lambda x: re.sub('[0-9]+', '', x))\n",
    "metadata['clean_title'] = metadata['clean_title'].apply(lambda x: re.sub(pattern, \" \", x).strip().lower())\n",
    "metadata['clean_title'] = metadata['clean_title'].apply(\n",
    "    lambda text: \" \".join([word for word in text.split() if word not in stopwords_plus])\n",
    ")\n",
    "\n",
    "#metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5429d180",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = metadata.groupby(by='clean_title', level=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb23d1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl_words = set(['wt', 'wildtype', 'control', 'cntrl', 'ctrl', 'uninfected', 'normal', 'untreated', 'unstimulated', 'shctrl', 'ctl', 'healthy', 'sictrl', 'sicontrol', 'ctr', 'wild', 'dmso', 'vehicle', 'naive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39be4c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupings = {}\n",
    "for label, group in groups:\n",
    "    if len(group) not in {3, 4}: #enforce 3-4 samples per group\n",
    "        raise ValueError(\"Study does not have 3-4 samples per group\")\n",
    "    \n",
    "    groupings[label] = group['geo_accession'].tolist()\n",
    "\n",
    "# print(groupings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28892de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_conditions = list(groupings.keys())\n",
    "title_ctrl = []\n",
    "for c in title_conditions:\n",
    "    if len(set(c.split()).intersection(ctrl_words)) > 0:\n",
    "        title_ctrl.append(c)\n",
    "        \n",
    "# print(title_conditions)\n",
    "# print(title_ctrl)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692d617b",
   "metadata": {},
   "outputs": [],
   "source": [
    "og_labels = {}\n",
    "labled_groupings = {}\n",
    "\n",
    "for label in groupings:\n",
    "    samps = groupings[label]\n",
    "    data = list(map(lambda s: s.lower(), metadata.loc[samps]['characteristics_ch1'].values))\n",
    "    data_clean = []\n",
    "    for d in data:\n",
    "        data_clean.append(set(filter(lambda w: w not in stopwords_plus, re.sub(pattern, ' ', d).split())))\n",
    "    condition = set(data_clean[0])\n",
    "    for s in data_clean[1:]:\n",
    "        condition.intersection_update(s)\n",
    "    condition = ' '.join(list(condition))\n",
    "    labled_groupings[condition] = samps\n",
    "    og_labels[condition] = label\n",
    "\n",
    "ch1_ctrl = []\n",
    "ch1_conditions = list(labled_groupings.keys())\n",
    "\n",
    "for condition in labled_groupings:\n",
    "    split_conditions = condition.lower().split()\n",
    "    if len(set(split_conditions).intersection(ctrl_words)) > 0:\n",
    "        ch1_ctrl.append(condition)\n",
    "\n",
    "# print(og_labels)\n",
    "# print(ch1_conditions)\n",
    "# print(ch1_ctrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d123545",
   "metadata": {},
   "outputs": [],
   "source": [
    "#must have 1-2 controls. Must have perturbation groups as well (not all groups can be controls).\n",
    "def check_eligibility(conditions, ctrl_conditions):\n",
    "    if len(ctrl_conditions) not in range(1, 3) or len(ctrl_conditions) == len(conditions):\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49301d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch1_eligibility = check_eligibility(ch1_conditions, ch1_ctrl)\n",
    "title_eligibility = check_eligibility(title_conditions, title_ctrl)\n",
    "#print(ch1_eligibility)\n",
    "#rint(title_eligibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6577b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_groups(title_ctrl, ch1_ctrl, og_labels):\n",
    "    #convert ch1 condition to corresponding title condition, check if their respective sample sets are equal\n",
    "    for c in ch1_ctrl:\n",
    "        ch1_corresponding = og_labels[c]\n",
    "        if set(groupings[ch1_corresponding]) != set(labled_groupings[c]):\n",
    "            return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c840df",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ch1_eligibility and title_eligibility:\n",
    "    if compare_groups(title_ctrl, ch1_ctrl, og_labels):\n",
    "        ctrl_conditions = title_ctrl\n",
    "        conditions = title_conditions\n",
    "    else:\n",
    "        raise Exception(\"Group Assignment Failed\")\n",
    "    \n",
    "elif ch1_eligibility ^ title_eligibility:\n",
    "    if ch1_eligibility:\n",
    "        ctrl_conditions = ch1_ctrl\n",
    "        conditions = ch1_conditions\n",
    "        groupings = labled_groupings\n",
    "    else:\n",
    "        ctrl_conditions = title_ctrl\n",
    "        conditions = title_conditions\n",
    "else:\n",
    "    raise Exception(\"Group Assignment Failed\")\n",
    "\n",
    "# print(ctrl_conditions)\n",
    "# print(conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8370bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "gene_matrix = a4.data.series(file, gse) #raw counts\n",
    "gene_matrix.to_csv(os.path.join(resource_path, \"raw_counts.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbe5209",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_matrix.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c872f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f\"**table {tab_num}**: This is a preview of the first 5 rows of the raw RNA-seq expression matrix from {gse}.\"))\n",
    "tab_num +=1\n",
    "display(FileLink(os.path.join(resource_path, \"raw_counts.csv\"), result_html_prefix=\"Download raw counts: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df8d119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove genes with all-zero counts\n",
    "filtered_matrix = gene_matrix.loc[gene_matrix.sum(axis=1) > 0, :]\n",
    "\n",
    "# Then filter out low average expression\n",
    "filtered_matrix = filtered_matrix.loc[filtered_matrix.mean(axis=1) >= 3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03fa065",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maayanlab_bioinformatics.normalization.log import log2_normalize\n",
    "from maayanlab_bioinformatics.normalization.zscore import zscore_normalize \n",
    "from maayanlab_bioinformatics.normalization.quantile_legacy import quantile_normalize\n",
    "\n",
    "def normalize(gene_counts):\n",
    "    norm_exp = quantile_normalize(gene_counts)\n",
    "    norm_exp = log2_normalize(norm_exp)\n",
    "    norm_exp = zscore_normalize(norm_exp)\n",
    "    return norm_exp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dd0900",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# from python_scripts.matrix import normalize\n",
    "norm_matrix = normalize(filtered_matrix) #normalize the matrix for dim reduction and clustergram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8da99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_matrix(expr_df, groupings, ctrl_conditions):\n",
    "    sampdict = {}\n",
    "    for group in groupings.keys():\n",
    "        samps = groupings[group]\n",
    "        for samp in samps:\n",
    "            if group in ctrl_conditions:\n",
    "                sampdict[samp] = \"control\"\n",
    "            else:\n",
    "                sampdict[samp] = \"perturbation\"\n",
    "    \n",
    "    annotat = pd.DataFrame.from_dict(sampdict, orient='index', columns=['group'])\n",
    "    anndict = {\n",
    "        'count': expr_df,\n",
    "        'annotations': annotat\n",
    "    }\n",
    "    return anndict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56663cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_norm_matrix = annotate_matrix(norm_matrix, groupings, ctrl_conditions)\n",
    "\n",
    "#print(annotated_norm_matrix['annotations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac29639a",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_matrix = annotate_matrix(filtered_matrix.astype('int64'), groupings, ctrl_conditions) #filtered but not normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4ab1ed",
   "metadata": {},
   "source": [
    "# **Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1262abd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_html = True #if true, render plotly graphs as html and embed with ipython. else, use fig.show()\n",
    "use_fig_plot = False #if true, render matplotlib graphs using show(), else it will render the saved pngs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4e33a4",
   "metadata": {},
   "source": [
    "## **Dimensionality Reduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8d6031",
   "metadata": {},
   "source": [
    "### **UMAP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3b5e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import python_scripts.visualizations as vis\n",
    "\n",
    "vis.plot(annotated_norm_matrix['count'], annotated_norm_matrix['annotations'], n_components=2, save_formats=save_formats, decomp=\"umap\", save_html=save_html, save_path=resource_path)\n",
    "#if save_html: display(HTML(os.path.join(resource_path, \"umap.html\")))\n",
    "display(Image(os.path.join(resource_path, \"umap.png\"), width=700))\n",
    "display(Markdown(f\"**Figure {fig_num}**: This figure displays a 2D scatter plot of a UMAP decomposition of the sample data. Each point represents an individual sample, colored by its experimental group.\"))\n",
    "fig_num+=1\n",
    "\n",
    "for fmt in save_formats:\n",
    "    display(FileLink(os.path.join(resource_path, f\"umap.{fmt}\"), result_html_prefix=f\"Download UMAP figure as {fmt}: \"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553629c1",
   "metadata": {},
   "source": [
    "### **PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f96056",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot(annotated_norm_matrix['count'], annotated_norm_matrix['annotations'], n_components=2, save_formats=save_formats, decomp=\"pca\", save_html=save_html, save_path=resource_path)\n",
    "#if save_html: display(HTML(os.path.join(resource_path, \"pca.html\")))\n",
    "display(Image(os.path.join(resource_path, \"pca.png\"), width=700))\n",
    "display(Markdown(f\"**Figure {fig_num}**: This figure displays a 2D scatter plot of a PCA decomposition of the sample data. Each point represents an individual sample, colored by its experimental group.\"))\n",
    "fig_num+=1\n",
    "\n",
    "for fmt in save_formats:\n",
    "    display(FileLink(os.path.join(resource_path, f\"pca.{fmt}\"), result_html_prefix=f\"Download PCA figure as {fmt}: \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cee26f0",
   "metadata": {},
   "source": [
    "### **t-SNE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e443a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.plot(annotated_norm_matrix['count'], annotated_norm_matrix['annotations'], n_components=2, save_formats=save_formats, decomp=\"tsne\", save_html=save_html, save_path=resource_path)\n",
    "#if save_html: display(HTML(os.path.join(resource_path, \"tsne.html\")))\n",
    "display(Image(os.path.join(resource_path, \"tsne.png\"), width=700))\n",
    "display(Markdown(f\"**Figure {fig_num}**: This figure displays a 2D scatter plot using a t-SNE decomposition of the sample data. Each point represents an individual sample, colored by its experimental group.\"))\n",
    "fig_num+=1\n",
    "\n",
    "for fmt in save_formats:\n",
    "    display(FileLink(os.path.join(resource_path, f\"tsne.{fmt}\"), result_html_prefix=f\"Download t-SNE figure as {fmt}: \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3a6b8f",
   "metadata": {},
   "source": [
    "## **Clustergram Heatmaps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b3bce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maayanlab_bioinformatics.normalization.filter import filter_by_var\n",
    "norm_t1000 = annotated_norm_matrix['count'].copy()\n",
    "norm_t1000 = filter_by_var(annotated_norm_matrix['count'], top_n=1000, axis=1)\n",
    "norm_t1000.columns=metadata['title'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd917d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1000_path = os.path.join(resource_path, 'expression_matrix_top1000_genes.txt')\n",
    "norm_t1000.to_csv(t1000_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25db3543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "clustergrammer_url = 'http://amp.pharm.mssm.edu/clustergrammer/matrix_upload/'\n",
    "\n",
    "r = requests.post(clustergrammer_url, files={'file': open(t1000_path, 'rb')})\n",
    "link = r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dd8308",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "display(IFrame(link, width=\"600\", height=\"650\"))\n",
    "display(Markdown(f\"**Figure {fig_num}**: The figure contains an interactive heatmap displaying gene expression for each sample in the RNA-seq dataset. Every row of the heatmap represents a gene, every column represents a sample, and every cell displays normalized gene expression values. The heatmap additionally features color bars beside each column which represent prior knowledge of each sample, such as the tissue of origin or experimental treatment.\"))\n",
    "fig_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6865cf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_scripts import visualizations as vis\n",
    "clustergram = vis.plot_clustergram(norm_t1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee4c0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fmt in save_formats:\n",
    "    file_name = os.path.join(resource_path, f\"clustergram.{fmt}\")\n",
    "    clustergram.write_image(file_name, width=700, height=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e5f16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if save_html:\n",
    "#     cluster_path = os.path.join(resource_path, \"clustergram.html\")\n",
    "#     clustergram.write_html(cluster_path)\n",
    "#     display(HTML(cluster_path))\n",
    "# else:\n",
    "#     clustergram.show()\n",
    "\n",
    "display(Image(os.path.join(resource_path, \"clustergram.png\"), width=700))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d0ed37",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f\"**Figure {fig_num}**: this figure is a clustergram produced with the graphing library Plotly. It sacrifices some interactivity for a more polished look.\"))\n",
    "fig_num+=1\n",
    "\n",
    "for fmt in save_formats:\n",
    "    file_name = os.path.join(resource_path, f\"clustergram.{fmt}\")\n",
    "    #clustergram.write_image(file_name, width=600, height=600)\n",
    "    display(FileLink(file_name, result_html_prefix=f\"Download as {fmt}: \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dde8700",
   "metadata": {},
   "source": [
    "## **Differentially Expressed Genes Calculation and Volcano Plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f6cfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maayanlab_bioinformatics.dge.limma_voom import limma_voom_differential_expression\n",
    "\n",
    "sig_names = []\n",
    "matrix = annotated_matrix['count']\n",
    "dges = {}\n",
    "\n",
    "seen = []\n",
    "for condition in ctrl_conditions:\n",
    "    for condition2 in conditions:\n",
    "        if condition!=condition2 and {condition, condition2} not in seen:\n",
    "            seen.append({condition, condition2})\n",
    "            \n",
    "            sig_name = f'{condition}-vs-{condition2}.tsv'\n",
    "            sig_names.append(sig_name)\n",
    "            try:\n",
    "                        with suppress_output():\n",
    "                            dge = limma_voom_differential_expression(\n",
    "                                matrix[groupings[condition]],\n",
    "                                matrix[groupings[condition2]],\n",
    "                                voom_design=True,\n",
    "                            )\n",
    "                        if not dge.empty:\n",
    "                            dge['logFC'] = dge['logFC'].round(2)\n",
    "                            dge['AveExpr'] = dge['AveExpr'].round(2)\n",
    "                            dge['t'] = dge['t'].round(2)\n",
    "                            dge['B'] = dge['B'].round(2)\n",
    "                            dges[sig_name] = dge\n",
    "                            dge.to_csv(os.path.join(resource_path, sig_name), sep='\\t')\n",
    "                        else:\n",
    "                            print('Empty dge returned for', sig_name)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print('Error computing:', sig_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1247cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sig_name in sig_names:\n",
    "    dge_path = os.path.join(resource_path, sig_name)\n",
    "    # table = pd.read_csv(dge_path, sep=\"\\t\")\n",
    "\n",
    "    table = dges[sig_name]\n",
    "    display(table.head(5))\n",
    "    display(Markdown(f\"**Table {tab_num}**: This is a preview of the first 5 rows of the differentially expressed gene table calculated by Limma Voom.\"))\n",
    "    display(FileLink(dge_path, result_html_prefix=\"Download DGE table: \"))\n",
    "    tab_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f017a148",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe207ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "upreg = {}\n",
    "downreg = {}\n",
    "\n",
    "upreg_t500 = {}\n",
    "downreg_t500 = {}\n",
    "\n",
    "for sig_name in sig_names:\n",
    "    #dge = pd.read_csv(os.path.join(resource_path, sig_name), sep=\"\\t\").set_index(\"gene_symbol\")\n",
    "    dge = dges[sig_name]\n",
    "\n",
    "    sig_name = sig_name.replace(\".tsv\", \"\")\n",
    "\n",
    "    up_genes = dge.loc[(dge['P.Value']<0.05) & (dge['logFC']>threshold), :].index.tolist() \n",
    "    down_genes = dge.loc[(dge['P.Value']<0.05) & (dge['logFC']<-threshold), :].index.tolist()\n",
    "\n",
    "    upreg[sig_name] = up_genes\n",
    "    downreg[sig_name] = down_genes\n",
    "\n",
    "    up_genes_t500 = dge.loc[(dge['P.Value']<0.05)].sort_values(by=\"logFC\", ascending=False)[:500].index.tolist()\n",
    "    down_genes_t500 = dge.loc[(dge['P.Value']<0.05)].sort_values(by=\"logFC\")[:500].index.tolist()\n",
    "\n",
    "    upreg_t500[sig_name] = up_genes_t500\n",
    "    downreg_t500[sig_name] = down_genes_t500\n",
    "\n",
    "    save_name = f\"{sig_name}_volcano\"\n",
    "\n",
    "    display(Markdown(f\"**{sig_name}**\"))\n",
    "    vis.plot_volcano(dge, threshold=threshold, save_formats=save_formats, save_name = save_name, save_html=save_html, save_path=resource_path)\n",
    "    #if save_html: display(HTML(os.path.join(resource_path, f\"{save_name}.html\")))\n",
    "    display(Image(os.path.join(resource_path, f\"{save_name}.png\"), width=700))\n",
    "    display(Markdown(f\"**Figure {fig_num}**: The figure contains an interactive scatter plot which displays the log2-fold changes and statistical significance of each gene calculated by performing a differential gene expression analysis for the comparison {sig_name}. Every point in the plot represents a gene. Red points indicate significantly up-regulated genes, blue points indicate down-regulated genes.\"))\n",
    "    fig_num+=1\n",
    "\n",
    "    for fmt in save_formats:\n",
    "        file_name=os.path.join(resource_path, f\"{save_name}.{fmt}\")\n",
    "        display(FileLink(file_name, result_html_prefix=f\"Download volcano plot as {fmt}: \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d048cdb3",
   "metadata": {},
   "source": [
    "## **Enrichr: Enrichment Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d9afc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_names_clean = [name.replace('.tsv', '') for name in sig_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b06a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_scripts.enrichment import Enrichr_API, enrichr_figure\n",
    "\n",
    "enrichr_libraries = [\"ChEA_2022\", \"ARCHS4_TFs_Coexp\", \"Reactome_Pathways_2024\", \"MGI_Mammalian_Phenotype_Level_4_2024\", \"GO_Biological_Process_2025\", \"GWAS_Catalog_2023\"]\n",
    "if species == \"human\":\n",
    "    enrichr_libraries.extend([\"WikiPathways_2024_Human\", \"KEGG_2021_Human\"])\n",
    "elif species == \"mouse\":\n",
    "    enrichr_libraries.extend([\"WikiPathways_2024_Mouse\", \"KEGG_2019_Mouse\"])\n",
    "else:\n",
    "    raise Exception(\"Species not supported.\")\n",
    "\n",
    "enrichr_libraries.sort()\n",
    "\n",
    "figure_file_format = save_formats\n",
    "\n",
    "color = \"tomato\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8abdcf9",
   "metadata": {},
   "source": [
    "### **Upregulated Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56a8c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "#upregulated results\n",
    "for sig_name in sig_names_clean:\n",
    "    up_file_name = sig_name + ' up_enrichr_results'\n",
    "    final_output_file_names_up = [str(os.path.join(resource_path, up_file_name+'.'+file_type)) for file_type in figure_file_format]\n",
    "    uresults = Enrichr_API(upreg[sig_name], enrichr_libraries)\n",
    "    display(Markdown(f\"#### **{sig_name}**\"))\n",
    "    enrichr_figure(uresults[0],uresults[1],uresults[2],final_output_file_names_up, uresults[4],figure_file_format, color, show_plot=False)\n",
    "    display(Image(final_output_file_names_up[0], width=600)) #display the PNG\n",
    "    display(Markdown(f'**Figure {fig_num}**: This figure contains several barplots depicting enrichment analysis results on the upregulated gene set. Each barplot corresponds to an individual library from Enrichr, and the top matching terms by p-value are depicted in each. Statistically significant terms are represented as red bars while others are represented as gray. Access your Enrichment results here: ' + str('https://amp.pharm.mssm.edu/Enrichr/enrich?dataset='+ uresults[3])))\n",
    "    fig_num+=1\n",
    "\n",
    "    for name in final_output_file_names_up: \n",
    "        display(FileLink(name, result_html_prefix=f\"Download figure as {name[name.rfind('.')+1:]}:\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d1c7d2",
   "metadata": {},
   "source": [
    "### **Downregulated Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca70ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#downregulated results\n",
    "for sig_name in sig_names_clean:\n",
    "    dn_file_name = sig_name + ' dn_enrichr_results'\n",
    "    final_output_file_names_dn = [str(os.path.join(resource_path, dn_file_name+'.'+file_type)) for file_type in figure_file_format]\n",
    "    dresults = Enrichr_API(downreg[sig_name], enrichr_libraries)\n",
    "    display(Markdown(f\"#### **{sig_name}**\"))\n",
    "    enrichr_figure(dresults[0],dresults[1],dresults[2],final_output_file_names_dn, dresults[4],figure_file_format, color, show_plot=False)\n",
    "    display(Image(final_output_file_names_dn[0], width=600)) #display the PNG\n",
    "    display(Markdown(f'**Figure {fig_num}**: This figure contains several barplots depicting enrichment analysis results on the upregulated gene set. Each barplot corresponds to an individual library from Enrichr, and the top matching terms by p-value are depicted in each. Statistically significant terms are represented as red bars while others are represented as gray. Access your Enrichment results here: ' + str('https://amp.pharm.mssm.edu/Enrichr/enrich?dataset='+ uresults[3])))\n",
    "    fig_num+=1\n",
    "\n",
    "    for name in final_output_file_names_dn: \n",
    "        display(FileLink(name, result_html_prefix=f\"Download figure as {name[name.rfind('.')+1:]}:\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3698c026",
   "metadata": {},
   "source": [
    "## **CHEA3: Transcription Factor Enrichment Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc3338c",
   "metadata": {},
   "source": [
    "### **Upregulated Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd6c33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import python_scripts.chea3 as chea\n",
    "\n",
    "#TFs of upregulated genes\n",
    "for sig_name in sig_names_clean:\n",
    "    save_name = sig_name + 'upchea'\n",
    "    up_results = chea.get_chea3_results(upreg[sig_name], 'query')\n",
    "    chea.mean_rank_bar(up_results, save_name=save_name, save_formats=save_formats, save_html=save_html, save_path=resource_path)\n",
    "    \n",
    "    display(Markdown(f\"#### **{sig_name}**\"))\n",
    "    #if save_html: display(HTML(os.path.join(resource_path, f\"{save_name}.html\")))\n",
    "    display(Image(os.path.join(resource_path, f\"{save_name}.png\"), width=700))\n",
    "    display(Markdown(f\"**Figure {fig_num}**: Horizontal bar chart, y-axis represents transcription factors. Displays the top ranked transcription factors for the upregulated set according to their average integrated scores across all the libraries.\"))\n",
    "    fig_num+=1\n",
    "\n",
    "    for fmt in save_formats:\n",
    "        file_name=os.path.join(resource_path, f\"{save_name}.{fmt}\")\n",
    "        display(FileLink(file_name, result_html_prefix=f\"Download bar plot as {fmt}: \"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab829a8c",
   "metadata": {},
   "source": [
    "### **Downregulated Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda97682",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sig_name in sig_names_clean:\n",
    "    save_name = sig_name + 'dnchea'\n",
    "    dn_results = chea.get_chea3_results(downreg[sig_name], 'query')\n",
    "    chea.mean_rank_bar(dn_results, save_name=save_name, save_formats=save_formats, save_html=save_html, save_path=resource_path)\n",
    "    \n",
    "    display(Markdown(f\"#### **{sig_name}**\"))\n",
    "    #if save_html: display(HTML(os.path.join(resource_path, f\"{save_name}.html\")))\n",
    "    display(Image(os.path.join(resource_path, f\"{save_name}.png\"), width=700))\n",
    "    display(Markdown(f\"**Figure {fig_num}**: Horizontal bar chart, y-axis represents transcription factors. Displays the top ranked transcription factors for the upregulated set according to their average integrated scores across all the libraries.\"))\n",
    "    fig_num+=1\n",
    "\n",
    "    for fmt in save_formats:\n",
    "        file_name=os.path.join(resource_path, f\"{save_name}.{fmt}\")\n",
    "        display(FileLink(file_name, result_html_prefix=f\"Download bar plot as {fmt}: \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16112608",
   "metadata": {},
   "source": [
    "## **L2S2 and DRUG-seqr: Reverser and Mimicker Drugs**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0e025b",
   "metadata": {},
   "source": [
    "### **Reverser Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc115f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_scripts.druganalysis import druganalysis\n",
    "\n",
    "dbs = ['l2s2_fda', 'l2s2_all', 'drugseqr_fda', 'drugseqr_all']\n",
    "\n",
    "for sig_name in sig_names_clean:\n",
    "    # up_genes_t500 = upreg_t500[sig_name]\n",
    "    # down_genes_t500 = downreg_t500[sig_name]\n",
    "    up_genes = upreg[sig_name]\n",
    "    down_genes = upreg[sig_name]\n",
    "    \n",
    "    rev_drugs = druganalysis(geneset=up_genes_t500, geneset_dn=down_genes_t500, direction=\"reversers\", save_path=resource_path, save_name=sig_name, tab_num=tab_num, fig_num=fig_num)\n",
    "    display(Markdown(f\"#### **{sig_name}**\"))\n",
    "    \n",
    "    for db in dbs:\n",
    "        display(Markdown(f\"**{db}**\"))\n",
    "        try:\n",
    "            rev_drugs.display_table(db=db)\n",
    "            rev_drugs.display_barplot(db=db, save_path=resource_path, save_formats=save_formats)\n",
    "        except ValueError as e:\n",
    "            print(\"Caught error: \", e)\n",
    "\n",
    "    fig_num = rev_drugs.fig_num\n",
    "    tab_num  = rev_drugs.tab_num\n",
    "\n",
    "    display(Markdown(\"---\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b731ddd",
   "metadata": {},
   "source": [
    "#### **Mimicker Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179d6f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sig_name in sig_names_clean:\n",
    "    # up_genes_t500 = upreg_t500[sig_name]\n",
    "    # down_genes_t500 = downreg_t500[sig_name]\n",
    "\n",
    "    up_genes = upreg[sig_name]\n",
    "    down_genes = upreg[sig_name]\n",
    "\n",
    "    mim_drugs = druganalysis(geneset=up_genes_t500, geneset_dn=down_genes_t500, direction=\"mimickers\", save_path=resource_path, save_name=sig_name, tab_num=tab_num, fig_num=fig_num)\n",
    "    display(Markdown(f\"#### **{sig_name}**\"))\n",
    "    \n",
    "    for db in dbs:\n",
    "        display(Markdown(f\"\\n**{db}**\"))\n",
    "        try:\n",
    "            mim_drugs.display_table(db=db)\n",
    "            mim_drugs.display_barplot(db=db, save_path=resource_path, save_formats=save_formats)\n",
    "        except ValueError as e:\n",
    "            print(\"Caught error: \", e)\n",
    "\n",
    "    fig_num = mim_drugs.fig_num\n",
    "    tab_num  = mim_drugs.tab_num\n",
    "\n",
    "    display(Markdown(\"---\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763ceac6",
   "metadata": {},
   "source": [
    "## **References**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c09889",
   "metadata": {},
   "outputs": [],
   "source": [
    "references = f'''\n",
    "[1] {citation}\n",
    "\n",
    "[2] McInnes L, Healy J, Saul N, Großberger L. UMAP: Uniform manifold approximation and projection. Journal of Open Source Software. 2018;3(29):861. doi:10.21105/joss.00861\n",
    "\n",
    "[3] Clark NR, Ma’ayan A. Introduction to statistical methods to analyze large data sets: Principal Components Analysis. Science Signaling. 2011;4(190):tr3-tr3. doi:10.1126/scisignal.2001967 \n",
    "\n",
    "[4] van der Maaten L, Hinton G. Visualizing Data using t-SNE. Journal of Machine Learning Research. 2008;9(86):2579-2605.\n",
    "\n",
    "[5] Chen EY, Tan CM, Kou Y, Duan Q, Wang Z, Meirelles GV, Clark NR, Ma'ayan A. Enrichr: interactive and collaborative HTML5 gene list enrichment analysis tool. BMC Bioinformatics. 2013;128(14)\n",
    "\n",
    "[6] Kuleshov MV, Jones MR, Rouillard AD, Fernandez NF, Duan Q, Wang Z, Koplev S, Jenkins SL, Jagodnik KM, Lachmann A, McDermott MG, Monteiro CD, Gundersen GW, Ma'ayan A. Enrichr: a comprehensive gene set enrichment analysis web server 2016 update. Nucleic Acids Research. 2016; gkw377.\n",
    "\n",
    "[7] Xie Z, Bailey A, Kuleshov MV, Clarke DJB., Evangelista JE, Jenkins SL, Lachmann A, Wojciechowicz ML, Kropiwnicki E, Jagodnik KM, Jeon M, & Ma’ayan A. Gene set knowledge discovery with Enrichr. Current Protocols, 1, e90. 2021. doi: 10.1002/cpz1.90\n",
    "\n",
    "[8] Keenan AB, Torre D, Lachmann A, Leong AK, Wojciechowicz M, Utti V, Jagodnik K, Kropiwnicki E, Wang Z, Ma'ayan A (2019) ChEA3: transcription factor enrichment analysis by orthogonal omics integration. Nucleic Acids Research. doi: 10.1093/nar/gkz446\n",
    "\n",
    "[9] Marino GB, Evangelista JE, Clarke DJB, Ma’ayan A. L2S2: chemical perturbation and CRISPR KO LINCS L1000 signature search engine. Nucleic Acids Res. 2025; gkaf373. doi:10.1093/nar/gkaf373\n",
    "\n",
    "[10] Li J, Ho DJ, Henault M, et al. DRUG-seq Provides Unbiased Biological Activity Readouts for Neuroscience Drug Discovery. ACS Chem Biol. 2022;17(6):1401-1414. doi:10.1021/acschembio.1c00920\n",
    "\n",
    "[11] Lachmann A, Torre D, Keenan AB, Jagodnik KM, Lee HJ, Wang L, Silverstein MC, Ma'ayan A. Massive mining of publicly available RNA-seq data from human and mouse. Nature Communications 9. Article number: 1366 (2018), doi: 10.1038/s41467-018-03751-6.\n",
    "\n",
    "[12] Bray, N., Pimentel, H., Melsted, P. et al. Near-optimal probabilistic RNA-seq quantification. Nat Biotechnol 34, 525–527 (2016). https://doi.org/10.1038/nbt.3519\n",
    "\n",
    "[13] Fernandez, N. F. et al. Clustergrammer, a web-based heatmap visualization and analysis tool for high-dimensional biological data. Sci. Data 4:170151 doi: 10.1038/sdata.2017.151 (2017).\n",
    "\n",
    "[14] Ritchie ME, Phipson B, Wu D, Hu Y, Law CW, Shi W, Smyth GK. limma powers differential expression analyses for RNA-sequencing and microarray studies. Nucleic Acids Res. 2015 Apr 20;43(7):e47. doi: 10.1093/nar/gkv007.\n",
    "\n",
    "[15] Milacic M, Beavers D, Conley P, Gong C, Gillespie M, Griss J, Haw R, Jassal B, Matthews L, May B, Petryszak R, Ragueneau E, Rothfels K, Sevilla C, Shamovsky V, Stephan R, Tiwari K, Varusai T, Weiser J, Wright A, Wu G, Stein L, Hermjakob H, D’Eustachio P. The Reactome Pathway Knowledgebase 2024. Nucleic Acids Research. 2024. doi: 10.1093/nar/gkad1025.\n",
    "\n",
    "[16] Eppig JT, Smith CL, Blake JA, Ringwald M, Kadin JA, Richardson JE, Bult CJ. Mouse Genome Informatics (MGI): Resources for Mining Mouse Genetic, Genomic, and Biological Data in Support of Primary and Translational Research. Methods Mol Biol. 2017;1488:47-73. doi: 10.1007/978-1-4939-6427-7_3.\n",
    "\n",
    "[17] Ashburner M, Ball CA, Blake JA, Botstein D, Butler H, Cherry JM, Davis AP, Dolinski K, Dwight SS, Eppig JT, Harris MA, Hill DP, Issel-Tarver L, Kasarskis A, Lewis S, Matese JC, Richardson JE, Ringwald M, Rubin GM, Sherlock G. Gene ontology: tool for the unification of biology. The Gene Ontology Consortium. Nat Genet. 2000 May;25(1):25-9. doi: 10.1038/75556.\n",
    "\n",
    "[18] Cerezo M, Sollis E, Ji Y, et al. The NHGRI-EBI GWAS Catalog: standards for reusability, sustainability and diversity. Nucleic Acids Res. 2025;53(D1):D998-D1005. doi:10.1093/nar/gkae1070\n",
    "\n",
    "[19] Kanehisa M, Furumichi M, Sato Y, Matsuura Y, Ishiguro-Watanabe M. KEGG: biological systems database as a model of the real world. Nucleic Acids Res. 2025;53(D1):D672-D677. doi:10.1093/nar/gkae909\n",
    "\n",
    "[20] Kanehisa M, Goto S. KEGG: kyoto encyclopedia of genes and genomes. Nucleic Acids Res. 2000;28(1):27-30. doi:10.1093/nar/28.1.27\n",
    "\n",
    "[21] Kanehisa M. Toward understanding the origin and evolution of cellular organisms. Protein Sci. 2019;28(11):1947-1951. doi:10.1002/pro.3715\n",
    "\n",
    "[22] Pico AR, Kelder T, van Iersel MP, Hanspers K, Conklin BR, Evelo C. WikiPathways: pathway editing for the people. PLoS Biol. 2008 Jul 22;6(7):e184. doi: 10.1371/journal.pbio.0060184.\n",
    "\n",
    "[23] GTEx Consortium. The Genotype-Tissue Expression (GTEx) project. Nat Genet. 2013 Jun;45(6):580-5. doi: 10.1038/ng.2653.\n",
    "\n",
    "[24] ENCODE Project Consortium. An integrated encyclopedia of DNA elements in the human genome. Nature. 2012;489(7414):57-74. doi:10.1038/nature11247\n",
    "\n",
    "[25] Luo Y, Hitz BC, Gabdank I, et al. New developments on the Encyclopedia of DNA Elements (ENCODE) data portal. Nucleic Acids Res. 2020;48(D1):D882-D889. doi:10.1093/nar/gkz1062\n",
    "\n",
    "[26] Hammal F, de Langen P, Bergon A, Lopez F, Ballester B. ReMap 2022: a database of Human, Mouse, Drosophila and Arabidopsis regulatory regions from an integrative analysis of DNA-binding sequencing experiments. Nucleic Acids Res. 2022;50(D1):D316-D325. doi:10.1093/nar/gkab996\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3dfa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(references))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9f59c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !jupyter nbconvert --to html --no-input \"{gse}.ipynb\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
