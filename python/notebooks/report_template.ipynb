{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9608ac7e",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#parameters for papermill to inject\n",
    "gse = \"GSE247175\"\n",
    "working_dir = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cafd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.path.isdir(working_dir):\n",
    "    os.chdir(working_dir)\n",
    "    #print(\"changed working dir\")\n",
    "else:\n",
    "    raise ValueError(\"not a valid directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8eca5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#no need to refresh kernel when changes are made to the helper scripts\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354864c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a9b40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from IPython.display import display,FileLink, Markdown, HTML, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65c3cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set to \"\" during production. Change only if you want to save images in a different directory.\n",
    "resource_path = \"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946e9a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def suppress_output(stdout=True, stderr=True, dest='/dev/null'):\n",
    "    ''' Usage:\n",
    "    with suppress_output():\n",
    "        print('hi')\n",
    "    '''\n",
    "    dev_null = open(dest, 'a')\n",
    "    if stdout:\n",
    "        _stdout = sys.stdout\n",
    "        sys.stdout = dev_null\n",
    "    if stderr:\n",
    "        _stderr = sys.stderr\n",
    "        sys.stderr = dev_null\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        if stdout:\n",
    "            sys.stdout = _stdout\n",
    "        if stderr:\n",
    "            sys.stderr = _stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75f0483",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['ENTREZ_EMAIL'] = os.getenv('ENTREZ_EMAIL')\n",
    "\n",
    "Entrez.email = os.environ['ENTREZ_EMAIL']\n",
    "\n",
    "id_handle = Entrez.esearch(db=\"gds\", term=f\"{gse}[Accession]\", retmax=1)\n",
    "id_record = Entrez.read(id_handle)\n",
    "gds_id = id_record[\"IdList\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf63e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = Entrez.esummary(db='gds', id=gds_id)\n",
    "record = Entrez.read(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e6e96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_species = {\n",
    "    \"homo sapiens\": \"human\",\n",
    "    \"mus musculus\": \"mouse\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44949fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "species = map_species[record[0]['taxon'].lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9738088",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(record[0]['PubMedIds'])==0: #discard studies with no pubmed citation\n",
    "    raise ValueError(\"No PubMed citation found for this study.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f934bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmid = int(record[0]['PubMedIds'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b1f071",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(record[0]['Samples']) not in range(6, 25): #discard studies that dont have 6-24 samples\n",
    "    raise ValueError(\"Number of samples need to be within 6-24.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98ce279",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_pubmed_metadata(pmid):\n",
    "    handle = Entrez.efetch(db=\"pubmed\", id=pmid, retmode=\"xml\")\n",
    "    records = Entrez.read(handle)\n",
    "    article = records['PubmedArticle'][0]['MedlineCitation']['Article']\n",
    "\n",
    "    title = article['ArticleTitle']\n",
    "    journal = article['Journal']['Title']\n",
    "    journal_abbr = article['Journal']['ISOAbbreviation']\n",
    "    year = article['Journal']['JournalIssue']['PubDate'].get('Year', '')\n",
    "    volume = article['Journal']['JournalIssue'].get('Volume', '')\n",
    "    issue = article['Journal']['JournalIssue'].get('Issue', '')\n",
    "    pages = article.get('Pagination', {}).get('MedlinePgn', '')\n",
    "    authors = article.get('AuthorList', [])\n",
    "\n",
    "    # def format_author(author):\n",
    "    #     initials = ''.join(author.get('Initials', ''))\n",
    "    #     return f\"{author['LastName']} {initials}\"\n",
    "\n",
    "    def format_author(author):\n",
    "        initials = '. '.join(author.get('Initials', '')) + '.'\n",
    "        return f\"{author['LastName']}, {initials}\"\n",
    "\n",
    "\n",
    "    authors = [format_author(a) for a in authors]\n",
    "\n",
    "    return {\n",
    "        \"title\": title,\n",
    "        \"journal\": journal,\n",
    "        \"year\": year,\n",
    "        \"volume\": volume,\n",
    "        \"issue\": issue,\n",
    "        \"pages\": pages,\n",
    "        \"authors\": authors\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1876f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmdict = fetch_pubmed_metadata(pmid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b00ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_apa_citation(metadata, pmid=None):\n",
    "    authors = metadata['authors']\n",
    "\n",
    "    if len(authors) <= 20:\n",
    "        if len(authors) > 1:\n",
    "            author_str = ', '.join(authors[:-1]) + ', & ' + authors[-1]\n",
    "        else:\n",
    "            author_str = authors[0]\n",
    "    else:\n",
    "        author_str = ', '.join(authors[:19]) + ', ... ' + authors[-1]\n",
    "\n",
    "    citation = (\n",
    "        f\"{author_str} ({metadata['year']}). {metadata['title']} \"\n",
    "        f\"*{metadata['journal']}*, {metadata['volume']}({metadata['issue']}), {metadata['pages']}.\"\n",
    "    )\n",
    "\n",
    "    if metadata.get('doi'):\n",
    "        citation += f\" https://doi.org/{metadata['doi']}\"\n",
    "    elif pmid:\n",
    "        citation += f\" PMID: {pmid}\"\n",
    "\n",
    "    return citation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5985ff11",
   "metadata": {},
   "outputs": [],
   "source": [
    "citation = format_apa_citation(pmdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5f160b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "#write a json file as a catalog list.\n",
    "metadata_path = \"metadata.json\"\n",
    "\n",
    "entry = {\n",
    "    \"id\": gse, \n",
    "    \"author\": \", \".join(pmdict['authors']),\n",
    "    \"year\": int(pmdict['year']),\n",
    "    \"species\": species,\n",
    "    \"title\": pmdict['title'],\n",
    "    \"pmid\": pmid,\n",
    "    \"num_samps\": len(record[0]['Samples']),\n",
    "    \"samples\": \", \".join(sorted([w['Accession'] for w in record[0]['Samples']])),\n",
    "    \"citation\": citation,\n",
    "    \"timestamp\": datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "with open(metadata_path, \"w\") as f:\n",
    "    json.dump(entry, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79709767",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f\"# **Reanalysis of \\\"{pmdict['title']}\\\" by {pmdict['authors'][0]} et al., {pmdict['journal']}, {pmdict['year']}**\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796adb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "link = f\"https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc={gse}\"\n",
    "display(Markdown(f\"{citation}\"))\n",
    "HTML(f'<a href=\"{link}\" target=\"_blank\">Visit GEO accession page</a>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7579908",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "client = genai.Client(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "#print(os.environ[\"GOOGLE_API_KEY\"])\n",
    "prompt = f'''\n",
    "  You are an expert academic writer. Your task is to reformat the provided research information into a concise abstract around 250 words following this exact template:\n",
    "\n",
    "  \"In this study, <FIRST AUTHOR> et al. [1] profiled <CELLS AND CONDITIONS> to further our understanding of <TOPIC>. The reanalysis of this dataset include <FILL IN>\"\n",
    "\n",
    "  Here is the contextual information:\n",
    "  Author: {pmdict['authors']}\n",
    "  Title: {pmdict['title']}\n",
    "  Summary: {record[0]['summary']}\n",
    "\n",
    "  In the reanalysis explanation, use the following information: the reanalysis is a full RNA-seq analysis pipeline that consists of: UMAP[2], PCA[3], t-SNE[4] plots of the samples; clustergram heatmap; differential gene expression analysis\n",
    "  for each pair of control and perturbation samples; Enrichment analysis for each gene signature using Enrichr [5, 6, 7]; Transcription factor analysis of gene signatures\n",
    "  using ChEA3 [8] ; Reverser and mimicker drug match analysis using L2S2 [9] and DRUG-seqr [10], both FDA and non-FDA approved. Results are provided as tables in addition to bar charts.\n",
    "\n",
    "  Please write the reanalysis as a complete paragraph with smoothly transitioning sentences. Use consistent, present tense.\n",
    "  Do not omit or change the ordering of the reference numbers.\n",
    "  Do not change the reference and insert it, in parentheses, where indicated. \n",
    "\n",
    "  Now, generate the abstract strictly following the template. Do not include any other text or introductory/concluding remarks.\n",
    "'''\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\", contents=prompt\n",
    ")\n",
    "#print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab7b2b0",
   "metadata": {},
   "source": [
    "## **Abstract**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9094c5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f\"{response.text}\\n*This abstract was generated with the assistance of Gemini 2.0 Flash.*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1091ef8",
   "metadata": {},
   "source": [
    "## **Methods**\n",
    "\n",
    "*RNA-seq alignment*\n",
    "\n",
    "Gene count matrices were obtained from ARCHS4 [11], which preprocessed the raw FASTQ data using the Kallisto [12] and STAR [] pseudoalignment algorithm.\n",
    "\n",
    "*Gene matrix processing* \n",
    "\n",
    "The raw gene matrix was filtered to remove genes that do not have an average of 3 reads across the samples. It was then quantile, log2, and z-score normalized. A regex-based function was used to infer whether individual samples belong to a “control” or a “perturbation” group by processing the metadata associated with each sample. \n",
    "\n",
    "*Dimensionality Reduction Visualization*\n",
    "\n",
    "Three types of dimensionality reduction techniques were applied on the processed expression matrices: UMAP[2], PCA[3], and t-SNE[4]. UMAP was calculated by the UMAP Python package and PCA and t-SNE were calculated using the Scikit-Learn Python library. The samples were then represented on 2D scatterplots.\n",
    "\n",
    "*Clustergram Heatmap*\n",
    "\n",
    "As a preliminary step, the top 1000 genes exhibiting most variability were selected. Using this new set, clustergram heatmaps were generated. Two versions of the clustergram exist: an interactive one generated by Clustergrammer [13] and a publication-ready alternative.\n",
    "\n",
    "*Differentially Expressed Genes Calculation and Volcano Plot*\n",
    "\n",
    "Differentially expressed genes between the control and perturbation samples were calculated using Limma Voom [14]. The logFC and -log10p values of each gene were visualized as a volcano scatterplot. Upregulated and downregulated genes were selected according to this criteria: p < 0.05 and |logFC| > 1.0.\n",
    "\n",
    "*Enrichr Enrichment Analysis*\n",
    "\n",
    "The upregulated and down-regulated sets were separately submitted to Enrichr [5, 6, 7]. These sets were compared against libraries from ChEA [8], ARCHS4 [12], Reactome Pathways [15], MGI Mammalian Phenotype [16], Gene Ontology Biological Processes [17], GWAS Catalog [18], KEGG [19, 20, 21], and WikiPathways [22]. The top matched terms from each library and their respective -log10p values were visualized as barplots.\n",
    "\n",
    "*Chea3 Transcription Factor Analysis*\n",
    "\n",
    "The upregulated and down-regulated sets were separately submitted to Chea3 [8]. These sets were compared against the libraries ARCHS4 Coexpression [12], GTEx Coexpression [23], Enrichr [5, 6, 7], ENCODE ChIP-seq [24, 25], ReMap ChIP-seq [26], and Literature-mined ChIP-seq. The top matched TFs were ranked according to their average score across each library and represented as barplots.\n",
    "\n",
    "*L2S2 and Drug-seqr drug analysis*\n",
    "\n",
    "The top 500 up and downregulated sets were submitted simulataneously to identify reverser and mimicker molecules, both FDA and non-FDA approved, from the L2S2 [9] and Drug-seqr [10] databases. The top matched molecules were compiled into tables and visualized as barplots. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d115ce0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_num = 1\n",
    "fig_num = 1\n",
    "save_formats = ['png', 'svg', 'jpeg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d05682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import archs4py as a4\n",
    "#file_path = a4.download.counts(\"human\", path=\"\", version=\"latest\") #comment out if the file is already downloaded\n",
    "file = os.path.join(\"/home/ajy20/projects/8--auto-playbook-geo-reports\", \"human_gene_v2.latest.h5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f101e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = a4.meta.series(file, gse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4326791",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "words_to_remove = ['experiement', 'tissue', 'type', 'batch', 'treatment', 'experiment', 'patient', 'batch', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "stopwords_plus = set(stopwords.words('english') + (words_to_remove))\n",
    "pattern = r'[-,_.:]'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e380c238",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_to_remove = [\"cell line\", \"cell type\", \"genotype\", \"treatment\"]\n",
    "\n",
    "\n",
    "pattern1 = r\"\\b(\" + \"|\".join(map(re.escape, terms_to_remove)) + r\")\\b\"\n",
    "\n",
    "metadata[\"cleaned_characteristics\"] = metadata[\"characteristics_ch1\"].str.replace(\n",
    "    pattern1, \n",
    "    \"\", \n",
    "    flags=re.IGNORECASE, \n",
    "    regex=True\n",
    ").str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "\n",
    "metadata['cleaned_characteristics'] = metadata['cleaned_characteristics'].apply(lambda x: re.sub(pattern, \" \", x).strip().lower())\n",
    "metadata['cleaned_characteristics'] = metadata['cleaned_characteristics'].apply(\n",
    "    lambda text: \" \".join([word for word in text.split() if word not in stopwords_plus])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c78e306",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['clean_title'] = metadata['title'].apply(lambda x: re.sub('[0-9]+', '', x))\n",
    "metadata['clean_title'] = metadata['clean_title'].apply(lambda x: re.sub(pattern, \" \", x).strip().lower())\n",
    "metadata['clean_title'] = metadata['clean_title'].apply(\n",
    "    lambda text: \" \".join([word for word in text.split() if word not in stopwords_plus])\n",
    ")\n",
    "\n",
    "#metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5429d180",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = metadata.groupby(by='clean_title', level=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb23d1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl_words = set(['wt', 'wildtype', 'control', 'cntrl', 'ctrl', 'uninfected', 'normal', 'untreated', 'unstimulated', 'shctrl', 'ctl', 'healthy', 'sictrl', 'sicontrol', 'ctr', 'wild', 'dmso', 'vehicle', 'naive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39be4c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupings = {}\n",
    "for label, group in groups:\n",
    "    if len(group) not in {3, 4}: #enforce 3-4 samples per group\n",
    "        raise ValueError(\"Study does not have 3-4 samples per group\")\n",
    "    \n",
    "    groupings[label] = group['geo_accession'].tolist()\n",
    "\n",
    "# print(groupings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28892de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_conditions = list(groupings.keys())\n",
    "title_ctrl = []\n",
    "for c in title_conditions:\n",
    "    if len(set(c.split()).intersection(ctrl_words)) > 0:\n",
    "        title_ctrl.append(c)\n",
    "        \n",
    "# print(title_conditions)\n",
    "# print(title_ctrl)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692d617b",
   "metadata": {},
   "outputs": [],
   "source": [
    "og_labels = {}\n",
    "labled_groupings = {}\n",
    "\n",
    "for label in groupings:\n",
    "    samps = groupings[label]\n",
    "    data = list(map(lambda s: s.lower(), metadata.loc[samps]['characteristics_ch1'].values))\n",
    "    data_clean = []\n",
    "    for d in data:\n",
    "        data_clean.append(set(filter(lambda w: w not in stopwords_plus, re.sub(pattern, ' ', d).split())))\n",
    "    condition = set(data_clean[0])\n",
    "    for s in data_clean[1:]:\n",
    "        condition.intersection_update(s)\n",
    "    condition = ' '.join(list(condition))\n",
    "    labled_groupings[condition] = samps\n",
    "    og_labels[condition] = label\n",
    "\n",
    "ch1_ctrl = []\n",
    "ch1_conditions = list(labled_groupings.keys())\n",
    "\n",
    "for condition in labled_groupings:\n",
    "    split_conditions = condition.lower().split()\n",
    "    if len(set(split_conditions).intersection(ctrl_words)) > 0:\n",
    "        ch1_ctrl.append(condition)\n",
    "\n",
    "# print(og_labels)\n",
    "# print(ch1_conditions)\n",
    "# print(ch1_ctrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d123545",
   "metadata": {},
   "outputs": [],
   "source": [
    "#must have 1-2 controls. Must have perturbation groups as well (not all groups can be controls).\n",
    "def check_eligibility(conditions, ctrl_conditions):\n",
    "    if len(ctrl_conditions) not in range(1, 3) or len(ctrl_conditions) == len(conditions):\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49301d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch1_eligibility = check_eligibility(ch1_conditions, ch1_ctrl)\n",
    "title_eligibility = check_eligibility(title_conditions, title_ctrl)\n",
    "#print(ch1_eligibility)\n",
    "#rint(title_eligibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6577b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if title and characteristic assignment determined the same controls\n",
    "def compare_groups(title_ctrl, ch1_ctrl, og_labels):\n",
    "    #convert ch1 condition to corresponding title condition, check if their respective sample sets are equal\n",
    "    for c in ch1_ctrl:\n",
    "        ch1_corresponding = og_labels[c]\n",
    "        if set(groupings[ch1_corresponding]) != set(labled_groupings[c]):\n",
    "            return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c840df",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ch1_eligibility and title_eligibility:\n",
    "    if compare_groups(title_ctrl, ch1_ctrl, og_labels):\n",
    "        ctrl_conditions = title_ctrl\n",
    "        conditions = title_conditions\n",
    "    else:\n",
    "        raise Exception(\"Group Assignment Failed\")\n",
    "    \n",
    "elif ch1_eligibility ^ title_eligibility:\n",
    "    if ch1_eligibility:\n",
    "        ctrl_conditions = ch1_ctrl\n",
    "        conditions = ch1_conditions\n",
    "        groupings = labled_groupings\n",
    "    else:\n",
    "        ctrl_conditions = title_ctrl\n",
    "        conditions = title_conditions\n",
    "else:\n",
    "    raise Exception(\"Group Assignment Failed\")\n",
    "\n",
    "# print(ctrl_conditions)\n",
    "# print(conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0fbba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "\n",
    "# Step 1: Send job\n",
    "url = \"https://maayanlab.cloud/sigpy/data/samples\"\n",
    "data = {\n",
    "    \"gsm_ids\": [w['Accession'] for w in record[0]['Samples']],\n",
    "    \"species\": species\n",
    "}\n",
    "response = requests.post(url, json=data)\n",
    "response.raise_for_status()\n",
    "task_id = response.json()['task_id']\n",
    "#print(\"Task ID:\", task_id)\n",
    "\n",
    "# Step 2: Poll for status\n",
    "status_url = f\"https://maayanlab.cloud/sigpy/data/samples/status/{task_id}\"\n",
    "\n",
    "max_attempts = 10\n",
    "sleep_sec = 2\n",
    "\n",
    "for attempt in range(max_attempts):\n",
    "    status_response = requests.get(status_url)\n",
    "    status_response.raise_for_status()\n",
    "    status = status_response.json().get('status')\n",
    "\n",
    "    #print(f\"[{attempt+1}] Status:\", status)\n",
    "    if status == 'SUCCESS':\n",
    "        break\n",
    "    elif status == 'FAILURE':\n",
    "        raise ValueError(\"Error getting matrix from ARCHS4.\")\n",
    "    \n",
    "    time.sleep(sleep_sec)\n",
    "    sleep_sec *= 1.5  # optional backoff\n",
    "else:\n",
    "    raise TimeoutError(\"Timed out waiting for ARCHS4 task to finish.\")\n",
    "\n",
    "# Step 3: Download result\n",
    "download_url = f\"https://maayanlab.cloud/sigpy/data/samples/download/{task_id}\"\n",
    "download_response = requests.get(download_url)\n",
    "with open(\"matrix.zip\", \"wb\") as f:\n",
    "    f.write(download_response.content)\n",
    "\n",
    "#print(\"✅ matrix.zip downloaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9161a047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "zip_file_path = 'matrix.zip'\n",
    "\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall()\n",
    "    extracted_files = zip_ref.namelist()\n",
    "\n",
    "gene_matrix = pd.read_csv(extracted_files[0], sep='\\t')\n",
    "gene_matrix.set_index(gene_matrix.columns[0], inplace=True)\n",
    "gene_matrix.index.name = None\n",
    "\n",
    "os.remove(zip_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbe5209",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_matrix.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c872f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f\"**table {tab_num}**: This is a preview of the first 5 rows of the raw RNA-seq expression matrix from {gse}.\"))\n",
    "tab_num +=1\n",
    "display(FileLink(os.path.join(resource_path, extracted_files[0]), result_html_prefix=\"Download raw counts: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df8d119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove genes with all-zero counts\n",
    "filtered_matrix = gene_matrix.loc[gene_matrix.sum(axis=1) > 0, :]\n",
    "\n",
    "# Then filter out low average expression\n",
    "filtered_matrix = filtered_matrix.loc[filtered_matrix.mean(axis=1) >= 3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03fa065",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maayanlab_bioinformatics.normalization.log import log2_normalize\n",
    "from maayanlab_bioinformatics.normalization.zscore import zscore_normalize \n",
    "from maayanlab_bioinformatics.normalization.quantile_legacy import quantile_normalize\n",
    "\n",
    "def normalize(gene_counts):\n",
    "    norm_exp = quantile_normalize(gene_counts)\n",
    "    norm_exp = log2_normalize(norm_exp)\n",
    "    norm_exp = zscore_normalize(norm_exp)\n",
    "    return norm_exp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dd0900",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "norm_matrix = normalize(filtered_matrix) #normalized counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8da99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_matrix(expr_df, groupings, ctrl_conditions):\n",
    "    sampdict = {}\n",
    "    for group in groupings.keys():\n",
    "        samps = groupings[group]\n",
    "        for samp in samps:\n",
    "            if group in ctrl_conditions:\n",
    "                sampdict[samp] = \"control\"\n",
    "            else:\n",
    "                sampdict[samp] = \"perturbation\"\n",
    "    \n",
    "    annotat = pd.DataFrame.from_dict(sampdict, orient='index', columns=['group'])\n",
    "    anndict = {\n",
    "        'count': expr_df,\n",
    "        'annotations': annotat\n",
    "    }\n",
    "    return anndict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56663cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_norm_matrix = annotate_matrix(norm_matrix, groupings, ctrl_conditions)\n",
    "\n",
    "#print(annotated_norm_matrix['annotations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac29639a",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_matrix = annotate_matrix(filtered_matrix.astype('int64'), groupings, ctrl_conditions) #filtered but not normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4ab1ed",
   "metadata": {},
   "source": [
    "# **Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1262abd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_html = True #if true, render plotly graphs as html and embed with ipython. else, use fig.show()\n",
    "use_fig_plot = False #if true, render matplotlib graphs using show(), else it will render the saved pngs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4e33a4",
   "metadata": {},
   "source": [
    "## **Dimensionality Reduction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c189f73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import dash_bio\n",
    "import sklearn\n",
    "from umap import UMAP\n",
    "import numpy as np\n",
    "import os\n",
    "import kaleido\n",
    "\n",
    "# import plotly.io as pio\n",
    "# from IPython.display import Image, display\n",
    "\n",
    "def plot(gene_counts, annotations, save_formats, n_components=2, decomp=\"pca\", save_html=False, save_path=\"\"):\n",
    "    \"\"\"\n",
    "    Plots a dimensionality reduction (PCA, t-SNE, or UMAP) of gene counts.\n",
    "\n",
    "    Args:\n",
    "        gene_counts (pd.DataFrame): A normalized gene counts matrix.\n",
    "        annotations (pd.DataFrame): Maps samples to its experimental group.\n",
    "        n_components (int): Number of components to plot (2 or 3).\n",
    "        decomp (str): Which decomposition to use: \"pca\", \"tsne\", or \"umap\".\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    decomp = decomp.lower()\n",
    "    gene_counts = gene_counts.T  # Ensure samples are rows\n",
    "\n",
    "    if(n_components not in [2, 3]):\n",
    "        raise ValueError(\"n_components must be either 2 or 3.\")\n",
    "\n",
    "    # Align annotations to gene_counts\n",
    "    annotations = annotations.reindex(gene_counts.index)\n",
    "\n",
    "    decomp = decomp.lower()\n",
    "    if decomp == \"pca\":\n",
    "        model = sklearn.decomposition.PCA(n_components=n_components)\n",
    "        projections = model.fit_transform(gene_counts)\n",
    "        total_variance = model.explained_variance_ratio_.sum() * 100\n",
    "        title = f'PCA of Gene Expression (Total Variance explained: {total_variance:.2f}%)'\n",
    "        labels = {str(i): f'PC{i+1} (variance explained: {model.explained_variance_ratio_[i]*100:.2f}%)' for i in range(n_components)}\n",
    "\n",
    "    elif decomp == \"tsne\":\n",
    "        perplexity = min(30, gene_counts.shape[0] - 1)\n",
    "        model = sklearn.manifold.TSNE(n_components=n_components, random_state=42, perplexity=perplexity)\n",
    "        projections = model.fit_transform(gene_counts.values)\n",
    "        title = 't-SNE of Gene Expression'\n",
    "        labels = {str(i): f't-SNE {i+1}' for i in range(n_components)}\n",
    "\n",
    "    elif decomp == \"umap\":\n",
    "        model = UMAP(n_components=n_components, random_state=42)\n",
    "        projections = model.fit_transform(gene_counts.values)\n",
    "        title = 'UMAP of Gene Expression'\n",
    "        labels = {str(i): f'UMAP {i+1}' for i in range(n_components)}\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"decomp must be one of: 'pca', 'tsne', or 'umap'.\")\n",
    "\n",
    "    if n_components == 2:\n",
    "        fig = px.scatter(\n",
    "            projections, x=0, y=1, color=annotations[\"group\"],\n",
    "            #title=title,\n",
    "            labels=labels, \n",
    "            hover_name=gene_counts.index,\n",
    "        )\n",
    "        fig.update_layout(\n",
    "            width=700,\n",
    "            height=500,\n",
    "            plot_bgcolor=\"rgba(0,0,0,0)\",\n",
    "            showlegend=True,\n",
    "            legend=dict(\n",
    "                title=\"\",\n",
    "                font=dict(\n",
    "                    size=14,\n",
    "                    family='Arial'\n",
    "                )\n",
    "            ),\n",
    "            # title=dict(\n",
    "            #     font=dict(\n",
    "            #         size=20\n",
    "            #     ),\n",
    "            #     x=0.5,\n",
    "            #     xanchor=\"center\"\n",
    "            # )\n",
    "        )\n",
    "        fig.update_xaxes(\n",
    "            showline=True,           \n",
    "            linecolor=\"black\",       \n",
    "            linewidth=2,             \n",
    "            showgrid=False,          \n",
    "            zeroline=False,\n",
    "            title=dict(\n",
    "                font=dict(\n",
    "                    size=20,\n",
    "                    family='Arial'\n",
    "                )\n",
    "            )       \n",
    "        )\n",
    "        fig.update_yaxes(\n",
    "            scaleanchor=\"x\",\n",
    "            scaleratio=1,\n",
    "            showline=True,\n",
    "            linecolor=\"black\",\n",
    "            linewidth=2,\n",
    "            showgrid=False,\n",
    "            zeroline=False,\n",
    "            title=dict(\n",
    "                font=dict(\n",
    "                    size=20,\n",
    "                    family='Arial'\n",
    "                ),\n",
    "                standoff=5\n",
    "            )\n",
    "        )\n",
    "    else: #support for 3D plots\n",
    "        fig = px.scatter_3d(\n",
    "            projections, x=0, y=1, z=2, color=annotations[\"group\"],\n",
    "            title=title, labels=labels, width=600, height=600\n",
    "        )\n",
    "        fig.update_scenes(\n",
    "            aspectmode=\"cube\",\n",
    "            xaxis=dict(\n",
    "                showline=True,\n",
    "                linecolor='lightgrey',\n",
    "                showbackground=False,\n",
    "                gridcolor='lightgrey',\n",
    "                zerolinecolor='black'\n",
    "            ),\n",
    "            yaxis=dict(\n",
    "                showline=True,\n",
    "                linecolor='lightgrey',\n",
    "                showbackground=False,\n",
    "                gridcolor='lightgrey',\n",
    "                zerolinecolor='black'\n",
    "            ),\n",
    "            zaxis=dict(\n",
    "                showline=True,\n",
    "                linecolor='lightgrey',\n",
    "                showbackground=False,\n",
    "                gridcolor='lightgrey',\n",
    "                zerolinecolor='black'\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    fig.update_traces(marker=dict(size=20))\n",
    "    \n",
    "    for f in save_formats:\n",
    "        fig_name = decomp + '.' + f\n",
    "        fig.write_image(os.path.join(save_path, fig_name), scale=2)\n",
    "\n",
    "    if save_html:\n",
    "        fig_name = decomp + \".html\"\n",
    "        fig.write_html(os.path.join(save_path, fig_name))\n",
    "    else:\n",
    "        fig.show()\n",
    "\n",
    "def plot_clustergram(gene_counts):\n",
    "    '''\n",
    "    Creates a reuasable Plotly Figure object that can be displayed in a Jupyter notebook.\n",
    "\n",
    "    Args: \n",
    "        gene_counts (DataFrame): a normalized, filtered gene count matrix.\n",
    "    \n",
    "    Returns:\n",
    "        plotly.graph_objs._figure.Figure: A clustergram in the form of a Plotly Figure\n",
    "    '''\n",
    "    \n",
    "    clustergram = dash_bio.Clustergram(\n",
    "        data = gene_counts,\n",
    "        column_labels = list(gene_counts.columns.values),\n",
    "        row_labels = list(gene_counts.index),\n",
    "        color_threshold={\n",
    "            'row': 250,\n",
    "            'col': 700\n",
    "        },\n",
    "        hidden_labels='row',\n",
    "        height = 800,\n",
    "        width = 600,\n",
    "        color_map= [\n",
    "            [0.0, '#636EFA'],\n",
    "            #[0.25, '#AB63FA'],\n",
    "            [0.5, '#FFFFFF'],\n",
    "            #[0.75, '#E763FA'],\n",
    "            [1.0, '#EF553B']\n",
    "        ],\n",
    "        row_dist = \"cosine\",\n",
    "        col_dist = \"cosine\",\n",
    "        link_method=\"average\",\n",
    "        paper_bg_color='#FFFFFF'\n",
    "    )\n",
    "    return clustergram\n",
    "\n",
    "def plot_volcano(deg, threshold, save_formats, save_name = \"volcano\", save_html=False, save_path=\"\"):\n",
    "    \n",
    "    deg['significance'] = \"insignificant\"\n",
    "    deg.loc[(deg['P.Value']<0.05) & (deg['logFC']<-threshold), 'significance'] = \"downregulated\"\n",
    "    deg.loc[(deg['P.Value']<0.05) & (deg['logFC']>threshold), 'significance'] = \"upregulated\"\n",
    "    \n",
    "    deg['-log10p'] = -np.log10(deg['P.Value'])\n",
    "\n",
    "    fig = px.scatter(\n",
    "        deg,\n",
    "        x='logFC',\n",
    "        y='-log10p',\n",
    "        color='significance',\n",
    "        color_discrete_map={\n",
    "            'insignificant': 'black',\n",
    "            'upregulated': 'red',\n",
    "            'downregulated': 'blue'\n",
    "        },\n",
    "        hover_name=deg.index,\n",
    "        #title=\"Control vs. Perturbation Signatures-Volcano Plot\",\n",
    "    )\n",
    "    #hide insignificant from the legend.\n",
    "    for trace in fig['data']:\n",
    "        if trace['name'] == 'insignificant':\n",
    "            trace['showlegend']=False\n",
    "\n",
    "    fig.update_layout(\n",
    "        width=600,\n",
    "        height=800,\n",
    "        plot_bgcolor=\"rgba(0,0,0,0)\",\n",
    "        # title=dict(\n",
    "        #     font=dict(\n",
    "        #         size=20\n",
    "        #     ),\n",
    "        #     x=0.5,\n",
    "        #     xanchor='center'\n",
    "        # ),\n",
    "        legend=dict(\n",
    "            title=\"\",\n",
    "            font=dict(\n",
    "                size=14,\n",
    "                family='Arial'\n",
    "            )\n",
    "        ),\n",
    "        font=dict(\n",
    "            family='Arial'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    max_abs_x = max(abs(deg['logFC'].min()), abs(deg['logFC'].max()))+0.5\n",
    "    max_y = deg['-log10p'].max()\n",
    "\n",
    "    fig.update_xaxes(\n",
    "        range=[-max_abs_x, max_abs_x],\n",
    "        zerolinecolor=\"black\",\n",
    "        zerolinewidth=1,\n",
    "        gridcolor=\"lightgrey\",\n",
    "        gridwidth=1,\n",
    "        title=dict(\n",
    "            font=dict(\n",
    "                size=20,\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        range=[0, max_y * 1.05],\n",
    "        zerolinecolor=\"black\",\n",
    "        zerolinewidth=1,\n",
    "        gridcolor=\"lightgrey\",\n",
    "        gridwidth=1,\n",
    "        title=dict(\n",
    "            font=dict(\n",
    "                size=20,\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    for fmt in save_formats:\n",
    "        fig_name = f\"{save_name}.{fmt}\"\n",
    "        fig.write_image(os.path.join(save_path, fig_name), scale=2)\n",
    "\n",
    "    if save_html:\n",
    "        fig.write_html(os.path.join(save_path, f\"{save_name}.html\"))\n",
    "    else:\n",
    "        fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8d6031",
   "metadata": {},
   "source": [
    "### **UMAP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3b5e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(annotated_norm_matrix['count'], annotated_norm_matrix['annotations'], n_components=2, save_formats=save_formats, decomp=\"umap\", save_html=save_html, save_path=resource_path)\n",
    "#if save_html: display(HTML(os.path.join(resource_path, \"umap.html\")))\n",
    "display(Image(os.path.join(resource_path, \"umap.png\"), width=700))\n",
    "display(Markdown(f\"**Figure {fig_num}**: This figure displays a 2D scatter plot of a UMAP decomposition of the sample data. Each point represents an individual sample, colored by its experimental group.\"))\n",
    "fig_num+=1\n",
    "\n",
    "for fmt in save_formats:\n",
    "    display(FileLink(os.path.join(resource_path, f\"umap.{fmt}\"), result_html_prefix=f\"Download UMAP figure as {fmt}: \"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553629c1",
   "metadata": {},
   "source": [
    "### **PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f96056",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(annotated_norm_matrix['count'], annotated_norm_matrix['annotations'], n_components=2, save_formats=save_formats, decomp=\"pca\", save_html=save_html, save_path=resource_path)\n",
    "#if save_html: display(HTML(os.path.join(resource_path, \"pca.html\")))\n",
    "display(Image(os.path.join(resource_path, \"pca.png\"), width=700))\n",
    "display(Markdown(f\"**Figure {fig_num}**: This figure displays a 2D scatter plot of a PCA decomposition of the sample data. Each point represents an individual sample, colored by its experimental group.\"))\n",
    "fig_num+=1\n",
    "\n",
    "for fmt in save_formats:\n",
    "    display(FileLink(os.path.join(resource_path, f\"pca.{fmt}\"), result_html_prefix=f\"Download PCA figure as {fmt}: \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cee26f0",
   "metadata": {},
   "source": [
    "### **t-SNE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e443a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(annotated_norm_matrix['count'], annotated_norm_matrix['annotations'], n_components=2, save_formats=save_formats, decomp=\"tsne\", save_html=save_html, save_path=resource_path)\n",
    "#if save_html: display(HTML(os.path.join(resource_path, \"tsne.html\")))\n",
    "display(Image(os.path.join(resource_path, \"tsne.png\"), width=700))\n",
    "display(Markdown(f\"**Figure {fig_num}**: This figure displays a 2D scatter plot using a t-SNE decomposition of the sample data. Each point represents an individual sample, colored by its experimental group.\"))\n",
    "fig_num+=1\n",
    "\n",
    "for fmt in save_formats:\n",
    "    display(FileLink(os.path.join(resource_path, f\"tsne.{fmt}\"), result_html_prefix=f\"Download t-SNE figure as {fmt}: \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3a6b8f",
   "metadata": {},
   "source": [
    "## **Clustergram Heatmaps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b3bce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maayanlab_bioinformatics.normalization.filter import filter_by_var\n",
    "norm_t1000 = annotated_norm_matrix['count'].copy()\n",
    "norm_t1000 = filter_by_var(annotated_norm_matrix['count'], top_n=1000, axis=1)\n",
    "norm_t1000.columns=metadata['title'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd917d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1000_path = os.path.join(resource_path, 'expression_matrix_top1000_genes.txt')\n",
    "norm_t1000.to_csv(t1000_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25db3543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "clustergrammer_url = 'https://maayanlab.cloud/clustergrammer/matrix_upload/'\n",
    "\n",
    "r = requests.post(clustergrammer_url, files={'file': open(t1000_path, 'rb')})\n",
    "link = r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dd8308",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "display(IFrame(link, width=\"600\", height=\"800\"))\n",
    "display(Markdown(f\"**Figure {fig_num}**: The figure contains an interactive heatmap displaying gene expression for each sample in the RNA-seq dataset. Every row of the heatmap represents a gene, every column represents a sample, and every cell displays normalized gene expression values. The heatmap additionally features color bars beside each column which represent prior knowledge of each sample, such as the tissue of origin or experimental treatment.\"))\n",
    "fig_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6865cf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustergram = plot_clustergram(norm_t1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee4c0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fmt in save_formats:\n",
    "    file_name = os.path.join(resource_path, f\"clustergram.{fmt}\")\n",
    "    clustergram.write_image(file_name, width=600, scale = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e5f16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if save_html:\n",
    "#     cluster_path = os.path.join(resource_path, \"clustergram.html\")\n",
    "#     clustergram.write_html(cluster_path)\n",
    "#     display(HTML(cluster_path))\n",
    "# else:\n",
    "#     clustergram.show()\n",
    "\n",
    "display(Image(os.path.join(resource_path, \"clustergram.png\"), width=700))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d0ed37",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f\"**Figure {fig_num}**: this figure is a clustergram produced with the graphing library Plotly. It sacrifices some interactivity for a more polished look.\"))\n",
    "fig_num+=1\n",
    "\n",
    "for fmt in save_formats:\n",
    "    file_name = os.path.join(resource_path, f\"clustergram.{fmt}\")\n",
    "    #clustergram.write_image(file_name, width=600, height=600)\n",
    "    display(FileLink(file_name, result_html_prefix=f\"Download as {fmt}: \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dde8700",
   "metadata": {},
   "source": [
    "## **Differentially Expressed Genes Calculation and Volcano Plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f6cfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maayanlab_bioinformatics.dge.limma_voom import limma_voom_differential_expression\n",
    "\n",
    "sig_names = []\n",
    "matrix = annotated_matrix['count']\n",
    "dges = {}\n",
    "\n",
    "seen = []\n",
    "for condition in ctrl_conditions:\n",
    "    for condition2 in conditions:\n",
    "        if condition!=condition2 and {condition, condition2} not in seen:\n",
    "            seen.append({condition, condition2})\n",
    "            \n",
    "            sig_name = f'{condition}-vs-{condition2}.tsv'\n",
    "            sig_names.append(sig_name)\n",
    "            try:\n",
    "                        with suppress_output():\n",
    "                            dge = limma_voom_differential_expression(\n",
    "                                matrix[groupings[condition]],\n",
    "                                matrix[groupings[condition2]],\n",
    "                                voom_design=True,\n",
    "                            )\n",
    "                        if not dge.empty:\n",
    "                            dge['logFC'] = dge['logFC'].round(2)\n",
    "                            dge['AveExpr'] = dge['AveExpr'].round(2)\n",
    "                            dge['t'] = dge['t'].round(2)\n",
    "                            dge['B'] = dge['B'].round(2)\n",
    "                            dges[sig_name] = dge\n",
    "                            dge.to_csv(os.path.join(resource_path, sig_name), sep='\\t')\n",
    "                        else:\n",
    "                            print('Empty dge returned for', sig_name)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print('Error computing:', sig_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1247cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sig_name in sig_names:\n",
    "    dge_path = os.path.join(resource_path, sig_name)\n",
    "    # table = pd.read_csv(dge_path, sep=\"\\t\")\n",
    "\n",
    "    table = dges[sig_name]\n",
    "    display(table.head(5))\n",
    "    display(Markdown(f\"**Table {tab_num}**: This is a preview of the first 5 rows of the differentially expressed gene table calculated by Limma Voom.\"))\n",
    "    display(FileLink(dge_path, result_html_prefix=\"Download DGE table: \"))\n",
    "    tab_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f017a148",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe207ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "upreg = {}\n",
    "downreg = {}\n",
    "\n",
    "upreg_t500 = {}\n",
    "downreg_t500 = {}\n",
    "\n",
    "for sig_name in sig_names:\n",
    "    #dge = pd.read_csv(os.path.join(resource_path, sig_name), sep=\"\\t\").set_index(\"gene_symbol\")\n",
    "    dge = dges[sig_name]\n",
    "\n",
    "    sig_name = sig_name.replace(\".tsv\", \"\")\n",
    "\n",
    "    up_genes = dge.loc[(dge['P.Value']<0.05) & (dge['logFC']>threshold), :].index.tolist() \n",
    "    down_genes = dge.loc[(dge['P.Value']<0.05) & (dge['logFC']<-threshold), :].index.tolist()\n",
    "\n",
    "    upreg[sig_name] = up_genes\n",
    "    downreg[sig_name] = down_genes\n",
    "\n",
    "    up_genes_t500 = dge.loc[(dge['P.Value']<0.05)].sort_values(by=\"logFC\", ascending=False)[:500].index.tolist()\n",
    "    down_genes_t500 = dge.loc[(dge['P.Value']<0.05)].sort_values(by=\"logFC\")[:500].index.tolist()\n",
    "\n",
    "    upreg_t500[sig_name] = up_genes_t500\n",
    "    downreg_t500[sig_name] = down_genes_t500\n",
    "\n",
    "    save_name = f\"{sig_name}_volcano\"\n",
    "\n",
    "    display(Markdown(f\"**{sig_name}**\"))\n",
    "    plot_volcano(dge, threshold=threshold, save_formats=save_formats, save_name = save_name, save_html=save_html, save_path=resource_path)\n",
    "    #if save_html: display(HTML(os.path.join(resource_path, f\"{save_name}.html\")))\n",
    "    display(Image(os.path.join(resource_path, f\"{save_name}.png\"), width=700))\n",
    "    display(Markdown(f\"**Figure {fig_num}**: The figure contains an interactive scatter plot which displays the log2-fold changes and statistical significance of each gene calculated by performing a differential gene expression analysis for the comparison {sig_name}. Every point in the plot represents a gene. Red points indicate significantly up-regulated genes, blue points indicate down-regulated genes.\"))\n",
    "    fig_num+=1\n",
    "\n",
    "    for fmt in save_formats:\n",
    "        file_name=os.path.join(resource_path, f\"{save_name}.{fmt}\")\n",
    "        display(FileLink(file_name, result_html_prefix=f\"Download volcano plot as {fmt}: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d9afc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_names_clean = [name.replace('.tsv', '') for name in sig_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d048cdb3",
   "metadata": {},
   "source": [
    "## **Enrichr: Enrichment Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57e9e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from IPython.display import display,FileLink, Markdown\n",
    "\n",
    "annot_dict = {}\n",
    "\n",
    "# Function to get Enrichr Results \n",
    "# Takes a gene list and Enrichr libraries as input \n",
    "def Enrichr_API(enrichr_gene_list, all_libraries):\n",
    "\n",
    "\n",
    "    all_terms = []\n",
    "    all_pvalues =[] \n",
    "    all_adjusted_pvalues = []\n",
    "    library_success = []\n",
    "    short_id = ''\n",
    "\n",
    "    for library_name in all_libraries : \n",
    "        ENRICHR_URL = 'http://amp.pharm.mssm.edu/Enrichr/addList'\n",
    "        genes_str = '\\n'.join(enrichr_gene_list)\n",
    "        description = 'Example gene list'\n",
    "        payload = {\n",
    "            'list': (None, genes_str),\n",
    "            'description': (None, description)\n",
    "        }\n",
    "\n",
    "        response = requests.post(ENRICHR_URL, files=payload)\n",
    "        if not response.ok:\n",
    "            raise Exception('Error analyzing gene list')\n",
    "\n",
    "        data = json.loads(response.text)\n",
    "        time.sleep(0.5)\n",
    "        ENRICHR_URL = 'http://amp.pharm.mssm.edu/Enrichr/enrich'\n",
    "        query_string = '?userListId=%s&backgroundType=%s'\n",
    "        user_list_id = data['userListId']\n",
    "        short_id = data[\"shortId\"]\n",
    "        gene_set_library = library_name\n",
    "        response = requests.get(\n",
    "            ENRICHR_URL + query_string % (user_list_id, gene_set_library)\n",
    "         )\n",
    "        if not response.ok:\n",
    "            raise Exception('Error fetching enrichment results')\n",
    "        try:\n",
    "            data = json.loads(response.text)\n",
    "            results_df  = pd.DataFrame(data[library_name][0:5])\n",
    "            all_terms.append(list(results_df[1]))\n",
    "            all_pvalues.append(list(results_df[2]))\n",
    "            all_adjusted_pvalues.append(list(results_df[6]))\n",
    "            library_success.append(library_name)\n",
    "        except:\n",
    "            print('Error for ' + library_name + ' library')\n",
    "\n",
    "    return([all_terms,all_pvalues,all_adjusted_pvalues,str(short_id),library_success])\n",
    "\n",
    "\n",
    "\n",
    "def enrichr_figure(all_terms,all_pvalues, all_adjusted_pvalues, plot_names, all_libraries, fig_format, bar_color, show_plot=True): \n",
    "    \n",
    "    # rows and columns depend on number of Enrichr libraries submitted \n",
    "    rows = []\n",
    "    cols = []\n",
    "    \n",
    "    # Bar colors\n",
    "    if bar_color!= 'lightgrey':\n",
    "        bar_color_not_sig = 'lightgrey'\n",
    "        edgecolor=None\n",
    "        linewidth=0\n",
    "    else:\n",
    "        bar_color_not_sig = 'white'\n",
    "        edgecolor='black'\n",
    "        linewidth=1\n",
    "    \n",
    "    # If only 1 Enrichr library selected, make simple plot \n",
    "    if len(all_libraries)==1:\n",
    "        #fig,axes = plt.subplots(1, 1,figsize=[8.5,6])\n",
    "        rows = [0]\n",
    "        cols = [0]\n",
    "        i = 0 \n",
    "        bar_colors = [bar_color if (x < 0.05) else bar_color_not_sig for x in all_pvalues[i]]\n",
    "        print(type(bar_colors))\n",
    "        fig = sns.barplot(x=np.log10(all_pvalues[i])*-1, y=all_terms[i], palette=bar_colors, edgecolor=edgecolor, linewidth=linewidth)\n",
    "        fig.axes.get_yaxis().set_visible(False)\n",
    "        fig.set_title(all_libraries[i].replace('_',' '),fontsize=26)\n",
    "        fig.set_xlabel('-Log10(p-value)',fontsize=25)\n",
    "        fig.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        fig.tick_params(axis='x', which='major', labelsize=20)\n",
    "        if max(np.log10(all_pvalues[i])*-1)<1:\n",
    "            fig.xaxis.set_ticks(np.arange(0, max(np.log10(all_pvalues[i])*-1), 0.1))\n",
    "        for ii,annot in enumerate(all_terms[i]):\n",
    "            if annot in annot_dict.keys():\n",
    "                annot = annot_dict[annot]\n",
    "            if all_adjusted_pvalues[i][ii] < 0.05:\n",
    "                annot = '  *'.join([annot, str(str(np.format_float_scientific(all_pvalues[i][ii],precision=2)))]) \n",
    "            else:\n",
    "                annot = '  '.join([annot, str(str(np.format_float_scientific(all_pvalues[i][ii],precision=2)))])\n",
    "\n",
    "            title_start= max(fig.axes.get_xlim())/200\n",
    "            fig.text(title_start,ii,annot,ha='left',wrap = True, fontsize = 26) #adjust font size\n",
    "            fig.patch.set_edgecolor('black')  \n",
    "            fig.patch.set_linewidth('2')\n",
    "        \n",
    "    \n",
    "    # If there are an even number of Enrichr libraries below 6\n",
    "    # Plots 1x2 or 2x2\n",
    "    else:\n",
    "        if len(all_libraries) % 2 == 0 and len(all_libraries) < 5:\n",
    "                for i in range(0,int(len(all_libraries)/2)):    \n",
    "                    rows = rows + [i]*2\n",
    "                    cols = list(range(0,2))*int(len(all_libraries)/2)    \n",
    "                fig, axes = plt.subplots(len(np.unique(rows)), len(np.unique(cols)),figsize=[7,int(2* len(np.unique(rows)))]) \n",
    "    \n",
    "        \n",
    "        # All other # of libraries 6 and above will have 3 columns and a flexible number of rows to accomodate all plots\n",
    "        else:\n",
    "            for i in range(0,int(np.ceil(len(all_libraries)/2))):\n",
    "                rows = rows + [i]*2\n",
    "                cols = list(range(0,2))*int(np.ceil(len(all_libraries)/2))\n",
    "            fig, axes = plt.subplots(len(np.unique(rows)), len(np.unique(cols)),figsize=[8,int(2* len(np.unique(rows)))])\n",
    "           \n",
    "        # If final figure only has one row...\n",
    "        if len(np.unique(rows))==1:\n",
    "            for i,library_name in enumerate(all_libraries):\n",
    "                bar_colors = [bar_color if (x < 0.05) else bar_color_not_sig for x in all_pvalues[i]]\n",
    "                sns.barplot(x=np.log10(all_pvalues[i])*-1, y=all_terms[i],ax=axes[i], palette=bar_colors, edgecolor=edgecolor, linewidth=linewidth)\n",
    "                axes[i].axes.get_yaxis().set_visible(False)\n",
    "                axes[i].set_title(library_name.replace('_',' '),fontsize=36)\n",
    "                axes[i].set_xlabel('-Log10(p-value)',fontsize=35)\n",
    "                axes[i].xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "                axes[i].tick_params(axis='x', which='major', labelsize=30)\n",
    "                if max(np.log10(all_pvalues[i])*-1)<1:\n",
    "                    axes[i].xaxis.set_ticks(np.arange(0, max(np.log10(all_pvalues[i])*-1), 0.1))\n",
    "                for ii,annot in enumerate(all_terms[i]):\n",
    "                    if annot in annot_dict.keys():\n",
    "                        annot = annot_dict[annot]\n",
    "                    if all_adjusted_pvalues[i][ii] < 0.05:\n",
    "                        annot = '  *'.join([annot, str(str(np.format_float_scientific(all_pvalues[i][ii],precision=2)))]) \n",
    "                    else:\n",
    "                        annot = '  '.join([annot, str(str(np.format_float_scientific(all_pvalues[i][ii],precision=2)))])\n",
    "\n",
    "                    title_start= max(axes[i].axes.get_xlim())/200\n",
    "                    axes[i].text(title_start,ii,annot,ha='left',wrap = True, fontsize = 36)\n",
    "                    axes[i].patch.set_edgecolor('black')  \n",
    "                    axes[i].patch.set_linewidth('2')\n",
    "\n",
    "            plt.subplots_adjust(top=4.5, right = 4.7,wspace = 0.03,hspace = 0.2)\n",
    "\n",
    "\n",
    "        # If the final figure has more than one row...\n",
    "        else:\n",
    "\n",
    "\n",
    "            for i,library_name in enumerate(all_libraries):\n",
    "                bar_colors = [bar_color if (x < 0.05) else bar_color_not_sig for x in all_pvalues[i]]\n",
    "                sns.barplot(x=np.log10(all_pvalues[i])*-1, y=all_terms[i],ax=axes[rows[i],cols[i]], palette=bar_colors, edgecolor=edgecolor, linewidth=linewidth)\n",
    "                axes[rows[i],cols[i]].axes.get_yaxis().set_visible(False)\n",
    "                axes[rows[i],cols[i]].set_title(library_name.replace('_',' '),fontsize=36)\n",
    "                axes[rows[i],cols[i]].set_xlabel('-Log10(p-value)',fontsize=35)\n",
    "                axes[rows[i],cols[i]].xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "                axes[rows[i],cols[i]].tick_params(axis='x', which='major', labelsize=30)\n",
    "                if max(np.log10(all_pvalues[i])*-1)<1:\n",
    "                    axes[rows[i],cols[i]].xaxis.set_ticks(np.arange(0, max(np.log10(all_pvalues[i])*-1), 0.1))\n",
    "                for ii,annot in enumerate(all_terms[i]):\n",
    "                    if annot in annot_dict.keys():\n",
    "                        annot = annot_dict[annot]\n",
    "                    if all_adjusted_pvalues[i][ii] < 0.05:\n",
    "                        annot = '  *'.join([annot, str(str(np.format_float_scientific(all_pvalues[i][ii],precision=2)))]) \n",
    "                    else:\n",
    "                        annot = '  '.join([annot, str(str(np.format_float_scientific(all_pvalues[i][ii],precision=2)))])\n",
    "\n",
    "                    title_start= max(axes[rows[i],cols[i]].axes.get_xlim())/200\n",
    "                    axes[rows[i],cols[i]].text(title_start,ii,annot,ha='left',wrap = True, fontsize = 30) #control bar text font size here\n",
    "                    axes[rows[i],cols[i]].patch.set_edgecolor('black')  \n",
    "                    axes[rows[i],cols[i]].patch.set_linewidth('2')\n",
    "\n",
    "            plt.subplots_adjust(top=4.8, right = 4.7,wspace = 0.03,hspace = 0.2)\n",
    "\n",
    "        # If >6 libraries are chosen and is not a multiple of 2, delete empty plots\n",
    "        if len(np.unique(rows))*len(np.unique(cols)) != len(all_libraries):\n",
    "            diff = (len(np.unique(rows))*len(np.unique(cols))) - len(all_libraries)\n",
    "            for i in range (1,int(diff+1)):\n",
    "                fig.delaxes(axes[rows[-i]][cols[-i]])\n",
    "    \n",
    "    # Save results \n",
    "    for plot_name in plot_names: \n",
    "        plt.savefig(plot_name,bbox_inches = 'tight')\n",
    "\n",
    "    # Show plot \n",
    "    if show_plot:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b06a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "enrichr_libraries = [\"ChEA_2022\", \"ARCHS4_TFs_Coexp\", \"Reactome_Pathways_2024\", \"MGI_Mammalian_Phenotype_Level_4_2024\", \"GO_Biological_Process_2025\", \"GWAS_Catalog_2023\"]\n",
    "if species == \"human\":\n",
    "    enrichr_libraries.extend([\"WikiPathways_2024_Human\", \"KEGG_2021_Human\"])\n",
    "elif species == \"mouse\":\n",
    "    enrichr_libraries.extend([\"WikiPathways_2024_Mouse\", \"KEGG_2019_Mouse\"])\n",
    "else:\n",
    "    raise Exception(\"Species not supported.\")\n",
    "\n",
    "enrichr_libraries.sort()\n",
    "\n",
    "figure_file_format = save_formats\n",
    "\n",
    "color = \"tomato\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8abdcf9",
   "metadata": {},
   "source": [
    "### **Upregulated Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56a8c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "#upregulated results\n",
    "for sig_name in sig_names_clean:\n",
    "    up_file_name = sig_name + ' up_enrichr_results'\n",
    "    final_output_file_names_up = [str(os.path.join(resource_path, up_file_name+'.'+file_type)) for file_type in figure_file_format]\n",
    "    uresults = Enrichr_API(upreg[sig_name], enrichr_libraries)\n",
    "    display(Markdown(f\"#### **{sig_name}**\"))\n",
    "    enrichr_figure(uresults[0],uresults[1],uresults[2],final_output_file_names_up, uresults[4],figure_file_format, color, show_plot=False)\n",
    "    display(Image(final_output_file_names_up[0], width=600)) #display the PNG\n",
    "    display(Markdown(f'**Figure {fig_num}**: This figure contains several barplots depicting enrichment analysis results on the upregulated gene set. Each barplot corresponds to an individual library from Enrichr, and the top matching terms by p-value are depicted in each. Statistically significant terms are represented as red bars while others are represented as gray. Access your Enrichment results here: ' + str('https://amp.pharm.mssm.edu/Enrichr/enrich?dataset='+ uresults[3])))\n",
    "    fig_num+=1\n",
    "\n",
    "    for name in final_output_file_names_up: \n",
    "        display(FileLink(name, result_html_prefix=f\"Download figure as {name[name.rfind('.')+1:]}:\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d1c7d2",
   "metadata": {},
   "source": [
    "### **Downregulated Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca70ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#downregulated results\n",
    "for sig_name in sig_names_clean:\n",
    "    dn_file_name = sig_name + ' dn_enrichr_results'\n",
    "    final_output_file_names_dn = [str(os.path.join(resource_path, dn_file_name+'.'+file_type)) for file_type in figure_file_format]\n",
    "    dresults = Enrichr_API(downreg[sig_name], enrichr_libraries)\n",
    "    display(Markdown(f\"#### **{sig_name}**\"))\n",
    "    enrichr_figure(dresults[0],dresults[1],dresults[2],final_output_file_names_dn, dresults[4],figure_file_format, color, show_plot=False)\n",
    "    display(Image(final_output_file_names_dn[0], width=600)) #display the PNG\n",
    "    display(Markdown(f'**Figure {fig_num}**: This figure contains several barplots depicting enrichment analysis results on the upregulated gene set. Each barplot corresponds to an individual library from Enrichr, and the top matching terms by p-value are depicted in each. Statistically significant terms are represented as red bars while others are represented as gray. Access your Enrichment results here: ' + str('https://amp.pharm.mssm.edu/Enrichr/enrich?dataset='+ uresults[3])))\n",
    "    fig_num+=1\n",
    "\n",
    "    for name in final_output_file_names_dn: \n",
    "        display(FileLink(name, result_html_prefix=f\"Download figure as {name[name.rfind('.')+1:]}:\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3698c026",
   "metadata": {},
   "source": [
    "## **CHEA3: Transcription Factor Enrichment Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abafc5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from tabulate import tabulate\n",
    "from IPython.display import HTML, display, Image, FileLink, Markdown\n",
    "import plotly.graph_objects as go\n",
    "import kaleido\n",
    "import os\n",
    "\n",
    "num_tfs = 10\n",
    "threshold =3\n",
    "\n",
    "def get_chea3_results(gene_set, query_name):\n",
    "    ADDLIST_URL = 'https://maayanlab.cloud/chea3/api/enrich/'\n",
    "    payload = {\n",
    "        'gene_set': gene_set,\n",
    "        'query_name': query_name\n",
    "    }\n",
    "    response = requests.post(ADDLIST_URL, data=json.dumps(payload))\n",
    "    if not response.ok: \n",
    "        # r.ok (where r is the object) returns whether the call to the url was successful\n",
    "        raise Exception('Error analyzing gene list')\n",
    "    sleep(1)\n",
    "    return json.loads(response.text) # .text returns the content of response in unicode\n",
    "\n",
    "# Function for displaying tables \n",
    "def display_tables(lib, description, results):\n",
    "    \n",
    "    for libname in lib:\n",
    "        display(HTML(f'<h3>{libname}</h3>'))\n",
    "        \n",
    "        table = [0] * num_tfs\n",
    "        tablecounter = 0\n",
    "        for i in results[libname][0:num_tfs]:\n",
    "            table[tablecounter] = [i['Rank'],\n",
    "                                   i['TF'],\n",
    "                                   f\"{i['Intersect']}/{i['Set length']}\", \n",
    "                                   i['FET p-value'], \n",
    "                                   i['FDR'], \n",
    "                                   i['Odds Ratio'],\n",
    "                                   f\"{', '.join(i['Overlapping_Genes'].split(',')[0:10])}, ...\"]\n",
    "            tablecounter += 1\n",
    "\n",
    "        display(HTML(tabulate(table, \n",
    "                              ['Rank', \n",
    "                               'TF', \n",
    "                               'Overlap', \n",
    "                               'FET p-value', \n",
    "                               'FDR', \n",
    "                               'Odds Ratio', \n",
    "                               'Overlapping Genes'], \n",
    "                              tablefmt='html')))\n",
    "        \n",
    "        display(HTML(f'<h5>{description[libname]}</h5>'))\n",
    "        \n",
    "        tsv_name = f\"{libname.replace(' ', '_')}.tsv\"\n",
    "        with open(tsv_name, 'w') as tsv_file:\n",
    "            tsv_file.write(tabulate(table, ['Rank', \n",
    "                                            'TF',\n",
    "                                            'Overlap', \n",
    "                                            'FET p-value', \n",
    "                                            'FDR', \n",
    "                                            'Odds Ratio', \n",
    "                                            'Overlapping Genes'], \n",
    "                                    tablefmt='tsv'))\n",
    "        display(HTML(f'<a href=\"{tsv_name}\">Download table in .tsv</a>'))\n",
    "        \n",
    "        \n",
    "# Function for displaying the individual library bar charts \n",
    "def display_charts(libs, description, results): \n",
    "    for libname in libs:\n",
    "        \n",
    "        display(HTML(f'<h3>{libname}</h3>'))\n",
    "        \n",
    "        tfs = [i['TF'] for i in results[libname]][0:num_tfs]\n",
    "        scores = [float(i['FET p-value']) for i in results[libname]][0:num_tfs]\n",
    "        \n",
    "        # reverse the order/ranking of the tfs (and their respective scores)\n",
    "        tfs = tfs[::-1]\n",
    "        scores = scores[::-1]\n",
    "\n",
    "        # takes the -log of the scores\n",
    "        scores = -np.log10(scores)\n",
    "\n",
    "        \n",
    "        score_range = max(scores) - min(scores)\n",
    "        x_lowerbound = min(scores) - (score_range * 0.05)\n",
    "        x_upperbound = max(scores) + (score_range * 0.05)\n",
    "        \n",
    "        libfig = go.Figure(data = go.Bar(name = libname, \n",
    "                                         x = scores, \n",
    "                                         y = tfs, \n",
    "                                         marker = go.bar.Marker(color = 'rgb(255,127,80)'), \n",
    "                                         orientation = 'h'))\n",
    "        libfig.update_layout(\n",
    "            title = {\n",
    "                'text':'Bar Chart of Scores based on FET p-values',\n",
    "                'y': 0.87,\n",
    "                'x': 0.5,\n",
    "                'xanchor':'center',\n",
    "                'yanchor':'top'\n",
    "            },\n",
    "            xaxis_title = '-log\\u2081\\u2080(FET p-value)', \n",
    "            # \\u208 unicode to get the subscript (need a subscript of \"10\")\n",
    "            yaxis_title = 'Transcription Factors',\n",
    "            font = dict(\n",
    "                size = 16,\n",
    "                color = 'black'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        libfig.update_xaxes(range = [x_lowerbound, x_upperbound])\n",
    "        \n",
    "        libfig.show()\n",
    "        \n",
    "        display(HTML(f'<h5>{description[libname]}</h5>'))\n",
    "        \n",
    "def indexfinder(lib_score_list, value):\n",
    "    index = 1\n",
    "    for num in lib_score_list:\n",
    "        if num == value:\n",
    "            return index\n",
    "        elif num != 0:\n",
    "            index += 1\n",
    "\n",
    "def mean_rank_bar(results, save_name, save_formats, save_html=False, save_path=\"\"):\n",
    "    c_lib_palette = {'ARCHS4 Coexpression':'rgb(196, 8, 8)',\n",
    "                 'ENCODE ChIP-seq':'rgb(244, 109, 67)',\n",
    "                 'Enrichr Queries':'rgb(242, 172, 68)', \n",
    "                 'GTEx Coexpression':'rgb(236, 252, 68)',\n",
    "                 'Literature ChIP-seq':'rgb(165, 242, 162)',\n",
    "                 'ReMap ChIP-seq':'rgb(92, 217, 78)'}\n",
    "    # this sets all the color values for all the libraries that will be displayed in the bar chart\n",
    "\n",
    "    # NOTE: removed Integrated mean/topRank since those are compiled from the above 6 libraries \n",
    "    # afterwards and so none of the TFs will have Integrated mean/topRank as one of their libraries\n",
    "\n",
    "    c_lib_means = {'ARCHS4 Coexpression': [0] * num_tfs, 'ENCODE ChIP-seq': [0] * num_tfs, \n",
    "                'Enrichr Queries': [0] * num_tfs, 'GTEx Coexpression': [0] * num_tfs,\n",
    "                'Literature ChIP-seq': [0] * num_tfs, 'ReMap ChIP-seq': [0] * num_tfs}\n",
    "    # creates a dictionary where each library is a key, and the values are empty lists with as\n",
    "    # many indices/spaces as the user has requested transcription factors (ex: if the user\n",
    "    # requests 15 TFs to be returned, the lists will have 15 spaces)\n",
    "\n",
    "\n",
    "    libs_sorted = ['ARCHS4 Coexpression','ENCODE ChIP-seq','Enrichr Queries',\n",
    "                'GTEx Coexpression','Literature ChIP-seq','ReMap ChIP-seq']\n",
    "\n",
    "\n",
    "\n",
    "    mr_results = results['Integrated--meanRank']\n",
    "    ###### NOTE: for meanRank, the TFs are already ranked by Score ######\n",
    "\n",
    "    for i in range(len(mr_results)):\n",
    "        for lib in libs_sorted:\n",
    "            mr_results[i].update({lib:0})\n",
    "            \n",
    "    for i in range(len(mr_results)):\n",
    "        thing = mr_results[i]['Library'].split(';')\n",
    "        for a in range(len(thing)):\n",
    "            library, value = thing[a].split(',')\n",
    "            mr_results[i].update({library:int(value)})\n",
    "        \n",
    "    sortedARCHS4 = sorted(mr_results, key = lambda k: k['ARCHS4 Coexpression'])\n",
    "    sortedGTEx = sorted(mr_results, key = lambda k: k['GTEx Coexpression']) \n",
    "    sortedEnrichr = sorted(mr_results, key = lambda k: k['Enrichr Queries']) \n",
    "    sortedENCODE = sorted(mr_results, key = lambda k: k['ENCODE ChIP-seq']) \n",
    "    sortedReMap = sorted(mr_results, key = lambda k: k['ReMap ChIP-seq']) \n",
    "    sortedLit = sorted(mr_results, key = lambda k: k['Literature ChIP-seq']) \n",
    "\n",
    "    rankedARCHS4 = [entry['ARCHS4 Coexpression'] for entry in sortedARCHS4]\n",
    "    rankedENCODE = [entry['ENCODE ChIP-seq'] for entry in sortedENCODE]\n",
    "    rankedEnrichr = [entry['Enrichr Queries'] for entry in sortedEnrichr] \n",
    "    rankedGTEx = [entry['GTEx Coexpression'] for entry in sortedGTEx]\n",
    "    rankedLit = [entry['Literature ChIP-seq'] for entry in sortedLit]\n",
    "    rankedReMap = [entry['ReMap ChIP-seq'] for entry in sortedReMap] \n",
    "\n",
    "\n",
    "    ranking_dict = {'ARCHS4 Coexpression':rankedARCHS4,\n",
    "                    'ENCODE ChIP-seq':rankedENCODE,\n",
    "                    'Enrichr Queries':rankedEnrichr,\n",
    "                    'GTEx Coexpression':rankedGTEx,\n",
    "                    'Literature ChIP-seq':rankedLit,\n",
    "                    'ReMap ChIP-seq':rankedReMap}\n",
    "\n",
    "    for tfentry in mr_results:\n",
    "        tfentry.update( [('SumRank', 0), ('AvgRank', 0) ])\n",
    "        library_scores = tfentry['Library'].split(';')\n",
    "        lib_counter = 0\n",
    "        for a in library_scores:\n",
    "            l, v = a.split(',')\n",
    "            v = int(v)\n",
    "            #scorerank = ranking_dict[l].index(v) + 1\n",
    "            scorerank = indexfinder(ranking_dict[l], int(v))\n",
    "            tfentry['SumRank'] += int(scorerank)\n",
    "            lib_counter += 1\n",
    "        tfentry['AvgRank'] = (tfentry['SumRank'] / lib_counter)\n",
    "        \n",
    "    sorted_results = sorted(mr_results, key = lambda k: k['AvgRank'])\n",
    "\n",
    "    sorted_top_results = []\n",
    "    index = 0\n",
    "    while (len(sorted_top_results) < num_tfs):\n",
    "        if len(sorted_results[index]['Library'].split(';')) >= threshold:\n",
    "            sorted_top_results.append(sorted_results[index])\n",
    "        index += 1\n",
    "        # moves on to the next index\n",
    "        \n",
    "    sorted_top_results = sorted_top_results[::-1]\n",
    "\n",
    "    # set up a list with all the TFs, sorted by rank (lowest to highest, in line with top_results)\n",
    "    sorted_tfs = []\n",
    "    for i in range(0, len(sorted_top_results)):\n",
    "        sorted_tfs.append(sorted_top_results[i].get('TF'))\n",
    "        # this pulls only the TF name from top_results and adds it to sorted_tfs\n",
    "\n",
    "    for i, tfentry in enumerate(sorted_top_results):\n",
    "        libscores = tfentry['Library'].split(';')\n",
    "        for a in libscores:\n",
    "            lib, value = a.split(',')\n",
    "            rank = indexfinder(ranking_dict[lib], int(value))\n",
    "            avg = tfentry['AvgRank']\n",
    "            tot = tfentry['SumRank']\n",
    "            bar_length = (rank*avg)/tot\n",
    "            c_lib_means[lib][i] = float(bar_length)\n",
    "\n",
    "    fig = go.Figure(data = [go.Bar(name = c_lib, \n",
    "                                x = c_lib_means[c_lib], \n",
    "                                y = sorted_tfs,\n",
    "                                marker = go.bar.Marker(color = c_lib_palette[c_lib]), \n",
    "                                orientation = 'h') \n",
    "                            for c_lib in libs_sorted])\n",
    "\n",
    "    fig.update_layout(barmode = 'stack')\n",
    "    fig.update_layout(\n",
    "        title = {\n",
    "            #'text': 'Stacked Bar Chart of Average Ranks in Different Libraries',\n",
    "            'text': '',\n",
    "            'y': 0.87,\n",
    "            'x': 0.5,\n",
    "            'xanchor': 'center',\n",
    "            'yanchor': 'top',\n",
    "        },\n",
    "        xaxis_title = 'Average of Ranks Across All Libraries',\n",
    "        yaxis_title = 'Transcription Factors',\n",
    "        font = dict(\n",
    "            size = 13,\n",
    "            color = 'black',\n",
    "            family = 'Arial'\n",
    "        ),\n",
    "        width=700,\n",
    "        margin=dict(\n",
    "            t=30\n",
    "        )\n",
    "    )\n",
    "\n",
    "    for fmt in save_formats: \n",
    "        file_name = save_name+'.'+fmt\n",
    "        fig.write_image(os.path.join(save_path, file_name), scale=2)\n",
    "\n",
    "    if save_html:\n",
    "        fig.write_html(os.path.join(save_path, f\"{save_name}.html\"))\n",
    "    else:\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc3338c",
   "metadata": {},
   "source": [
    "### **Upregulated Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd6c33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TFs of upregulated genes\n",
    "for sig_name in sig_names_clean:\n",
    "    save_name = sig_name + '_upchea'\n",
    "    up_results = get_chea3_results(upreg[sig_name], 'query')\n",
    "    mean_rank_bar(up_results, save_name=save_name, save_formats=save_formats, save_html=save_html, save_path=resource_path)\n",
    "    \n",
    "    display(Markdown(f\"#### **{sig_name}**\"))\n",
    "    #if save_html: display(HTML(os.path.join(resource_path, f\"{save_name}.html\")))\n",
    "    display(Image(os.path.join(resource_path, f\"{save_name}.png\"), width=700))\n",
    "    display(Markdown(f\"**Figure {fig_num}**: Horizontal bar chart, y-axis represents transcription factors. Displays the top ranked transcription factors for the upregulated set according to their average integrated scores across all the libraries.\"))\n",
    "    fig_num+=1\n",
    "\n",
    "    for fmt in save_formats:\n",
    "        file_name=os.path.join(resource_path, f\"{save_name}.{fmt}\")\n",
    "        display(FileLink(file_name, result_html_prefix=f\"Download bar plot as {fmt}: \"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab829a8c",
   "metadata": {},
   "source": [
    "### **Downregulated Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda97682",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sig_name in sig_names_clean:\n",
    "    save_name = sig_name + '_dnchea'\n",
    "    dn_results = get_chea3_results(downreg[sig_name], 'query')\n",
    "    mean_rank_bar(dn_results, save_name=save_name, save_formats=save_formats, save_html=save_html, save_path=resource_path)\n",
    "    \n",
    "    display(Markdown(f\"#### **{sig_name}**\"))\n",
    "    #if save_html: display(HTML(os.path.join(resource_path, f\"{save_name}.html\")))\n",
    "    display(Image(os.path.join(resource_path, f\"{save_name}.png\"), width=700))\n",
    "    display(Markdown(f\"**Figure {fig_num}**: Horizontal bar chart, y-axis represents transcription factors. Displays the top ranked transcription factors for the upregulated set according to their average integrated scores across all the libraries.\"))\n",
    "    fig_num+=1\n",
    "\n",
    "    for fmt in save_formats:\n",
    "        file_name=os.path.join(resource_path, f\"{save_name}.{fmt}\")\n",
    "        display(FileLink(file_name, result_html_prefix=f\"Download bar plot as {fmt}: \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16112608",
   "metadata": {},
   "source": [
    "## **L2S2 and DRUG-seqr: Reverser and Mimicker Drugs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d5a4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# from matplotlib_venn import venn2\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import seaborn as sns\n",
    "# from scipy.stats import fisher_exact\n",
    "from IPython.display import HTML, display, Markdown, FileLink, Image\n",
    "import os\n",
    "pd.set_option('display.float_format', '{:.2e}'.format)\n",
    "\n",
    "class druganalysis:\n",
    "    def __init__(self, geneset, geneset_dn, save_path, save_name=\"\", direction=\"down-regulators\", tab_num=1, fig_num=1):\n",
    "        self.direction=direction\n",
    "        self.save_path=save_path\n",
    "        self.save_name = save_name\n",
    "        self.fig_num=fig_num\n",
    "        self.tab_num=tab_num\n",
    "        if self.direction == 'up-regulators' or self.direction == 'mimickers':\n",
    "            self.direction_str = 'up'\n",
    "        else:\n",
    "            self.direction_str = 'down'\n",
    "\n",
    "        self.geneset = self.get_l2s2_valid_genes(geneset)\n",
    "        self.geneset_dn = self.get_l2s2_valid_genes(geneset_dn)\n",
    "\n",
    "        if len(geneset) == 0 or len(geneset_dn) == 0:\n",
    "            raise ValueError(\"Insufficient genes in the input gene sets that overlap with the L2S2 database.\")\n",
    "        \n",
    "        self.l2s2_geneset_up_id, self.l2s2_geneset_dn_id = self.add_user_geneset(self.geneset, geneset_dn=self.geneset_dn)\n",
    "        self.drugseqr_geneset_up_id, self.drugseqr_geneset_dn_id = self.add_user_geneset(self.geneset, geneset_dn=self.geneset_dn, url=\"http://drugseqr.maayanlab.cloud/graphql\")\n",
    "        \n",
    "        self.l2s2_df = self.enrich_up_down(self.geneset, self.geneset_dn, first=500).dropna()\n",
    "        self.drugseqr_df = self.enrich_up_down(self.geneset, self.geneset_dn, url=\"http://drugseqr.maayanlab.cloud/graphql\", first=500).dropna()\n",
    "\n",
    "        self.l2s2_df_nofda = self.enrich_up_down(self.geneset, self.geneset_dn, first=500, fda_approved=False).dropna()\n",
    "        self.drugseqr_df_nofda = self.enrich_up_down(self.geneset, self.geneset_dn, url=\"http://drugseqr.maayanlab.cloud/graphql\", first=500, fda_approved=False).dropna()\n",
    "        \n",
    "        # if self.l2s2_df.empty and self.drugseqr_df.empty:\n",
    "        #     raise ValueError(\"No results found for the provided gene set(s).\")\n",
    "\n",
    "        # self.l2s2_df['perturbation'] =self.l2s2_df['term'].apply(lambda x: x.split('_')[4].lower() if len(x.split('_')) > 4 else None)\n",
    "        # self.drugseqr_df['perturbation'] = self.drugseqr_df['term'].apply(lambda x: x.split('_')[0].lower() if len(x.split('_')) > 0 else None)\n",
    "        # self.l2s2_df_nofda['perturbation'] = self.l2s2_df_nofda['term'].apply(lambda x: x.split('_')[4] if len(x.split('_')) > 4 else None)\n",
    "        # self.drugseqr_df_nofda['perturbation'] = self.drugseqr_df_nofda['term'].apply(lambda x: x.split('_')[0].lower() if len(x.split('_')) > 0 else None)\n",
    "\n",
    "        if not self.l2s2_df.empty:\n",
    "            self.l2s2_df['perturbation'] =self.l2s2_df['term'].apply(lambda x: x.split('_')[4].lower() if len(x.split('_')) > 4 else None)\n",
    "        # else:\n",
    "        #     print(\"no FDA-approved L2S2 drugs.\")\n",
    "\n",
    "        if not self.l2s2_df_nofda.empty:\n",
    "            self.l2s2_df_nofda['perturbation'] = self.l2s2_df_nofda['term'].apply(lambda x: x.split('_')[4] if len(x.split('_')) > 4 else None)\n",
    "        # else:\n",
    "        #     print(\"no L2S2 drugs.\")\n",
    "\n",
    "        if not self.drugseqr_df.empty:\n",
    "            self.drugseqr_df['perturbation'] = self.drugseqr_df['term'].apply(lambda x: x.split('_')[0].lower() if len(x.split('_')) > 0 else None)\n",
    "        # else:\n",
    "        #     print(\"no FDA-approved DRUG-seqr drugs.\")\n",
    "\n",
    "        if not self.drugseqr_df_nofda.empty:\n",
    "            self.drugseqr_df_nofda['perturbation'] = self.drugseqr_df_nofda['term'].apply(lambda x: x.split('_')[0].lower() if len(x.split('_')) > 0 else None)\n",
    "        # else:\n",
    "        #     print(\"no DRUG-seqr drugs.\")\n",
    "        \n",
    "\n",
    "\n",
    "    def enrich_single_set(self, geneset: list, first=500, url=\"http://l2s2.maayanlab.cloud/graphql\", fda_approved=True):\n",
    "        query = {\n",
    "        \"operationName\": \"EnrichmentQuery\",\n",
    "        \"variables\": {\n",
    "            \"filterTerm\": f\" {self.direction_str}\",\n",
    "            \"offset\": 0,\n",
    "            \"first\": first,\n",
    "            \"filterFda\": fda_approved,\n",
    "            \"sortBy\": \"pvalue\",\n",
    "            \"genes\": geneset,\n",
    "        },\n",
    "        \"query\": \"\"\"query EnrichmentQuery(\n",
    "                        $genes: [String]!\n",
    "                        $filterTerm: String = \"\"\n",
    "                        $offset: Int = 0\n",
    "                        $first: Int = 10\n",
    "                        $filterFda: Boolean = false\n",
    "                        $sortBy: String = \"\"\n",
    "                        ) {\n",
    "                        currentBackground {\n",
    "                            enrich(\n",
    "                            genes: $genes\n",
    "                            filterTerm: $filterTerm\n",
    "                            offset: $offset\n",
    "                            first: $first\n",
    "                            filterFda: $filterFda\n",
    "                            sortby: $sortBy\n",
    "                            ) {\n",
    "                            nodes {\n",
    "                                geneSetHash\n",
    "                                pvalue\n",
    "                                adjPvalue\n",
    "                                oddsRatio\n",
    "                                nOverlap\n",
    "                                geneSets {\n",
    "                                nodes {\n",
    "                                    term\n",
    "                                    id\n",
    "                                    nGeneIds\n",
    "                                    geneSetFdaCountsById {\n",
    "                                    nodes {\n",
    "                                        approved\n",
    "                                        count\n",
    "                                    }\n",
    "                                    }\n",
    "                                }\n",
    "                                totalCount\n",
    "                                }\n",
    "                            }\n",
    "                            totalCount\n",
    "                            }\n",
    "                        }\n",
    "                        }\n",
    "                        \"\"\",\n",
    "        }\n",
    "\n",
    "        headers = {\n",
    "            \"Accept\": \"application/json\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "\n",
    "        response = requests.post(url, data=json.dumps(query), headers=headers)\n",
    "        response.raise_for_status()\n",
    "        res = response.json()\n",
    "\n",
    "        enrichment = res['data']['currentBackground']['enrich']['nodes']# %%\n",
    "\n",
    "        df_enrichment = pd.json_normalize(\n",
    "            enrichment, \n",
    "            record_path=['geneSets', 'nodes'], \n",
    "            meta=['geneSetHash', 'pvalue', 'adjPvalue', 'oddsRatio', 'nOverlap']\n",
    "        )\n",
    "\n",
    "        if df_enrichment.empty:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        df_enrichment[\"approved\"] = df_enrichment[\"geneSetFdaCountsById.nodes\"].map(lambda x: x[0]['approved'] if len(x) > 0 else False)\n",
    "        df_enrichment[\"count\"] = df_enrichment[\"geneSetFdaCountsById.nodes\"].map(lambda x: x[0]['count'] if len(x) > 0 else 0)\n",
    "        df_enrichment.drop(columns=['geneSetFdaCountsById.nodes'], inplace=True)\n",
    "\n",
    "        return df_enrichment\n",
    "\n",
    "    def enrich_up_down(self, genes_up: list[str], genes_down: list[str], first=500, url=\"http://l2s2.maayanlab.cloud/graphql\", fda_approved=True):\n",
    "        query = {\n",
    "            \"operationName\": \"PairEnrichmentQuery\",\n",
    "            \"variables\": {\n",
    "            \"filterTerm\": f\" {self.direction_str}\",\n",
    "            \"offset\": 0,\n",
    "            \"first\": first,\n",
    "            \"filterFda\": fda_approved,\n",
    "            \"sortBy\": \"pvalue_mimic\" if self.direction_str == \"up\" else \"pvalue_reverse\",\n",
    "            \"pvalueLe\": 0.05,\n",
    "            \"genesUp\": genes_up,\n",
    "            \"genesDown\": genes_down\n",
    "            },\n",
    "            \"query\": \"\"\"query PairEnrichmentQuery($genesUp: [String]!, $genesDown: [String]!, $filterTerm: String = \"\", $offset: Int = 0, $first: Int = 10, $filterFda: Boolean = false, $sortBy: String = \"\", $pvalueLe: Float = 0.05) {{\n",
    "                            currentBackground {{\n",
    "                                {}(\n",
    "                                filterTerm: $filterTerm\n",
    "                                offset: $offset\n",
    "                                first: $first\n",
    "                                filterFda: $filterFda\n",
    "                                sortby: $sortBy\n",
    "                                pvalueLe: $pvalueLe\n",
    "                                genesDown: $genesDown\n",
    "                                genesUp: $genesUp\n",
    "                                ) {{\n",
    "                                totalCount\n",
    "                                nodes {{\n",
    "                                    adjPvalueMimic\n",
    "                                    adjPvalueReverse\n",
    "                                    mimickerOverlap\n",
    "                                    oddsRatioMimic\n",
    "                                    oddsRatioReverse\n",
    "                                    pvalueMimic\n",
    "                                    pvalueReverse\n",
    "                                    reverserOverlap\n",
    "                                    geneSet {{\n",
    "                                    nodes {{\n",
    "                                        id\n",
    "                                        nGeneIds\n",
    "                                        term\n",
    "                                        geneSetFdaCountsById {{\n",
    "                                        nodes {{\n",
    "                                            count\n",
    "                                            approved\n",
    "                                        }}\n",
    "                                        }}\n",
    "                                    }}\n",
    "                                    }}\n",
    "                                }}\n",
    "                                }}\n",
    "                            }}\n",
    "                            }}\"\"\".format(\"pairedEnrich\" if 'l2s2' in url else \"pairEnrich\")\n",
    "        }\n",
    "\n",
    "        headers = {\n",
    "                \"Accept\": \"application/json\",\n",
    "                \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "\n",
    "        response = requests.post(url, data=json.dumps(query), headers=headers)\n",
    "\n",
    "        response.raise_for_status()\n",
    "        res = response.json()\n",
    "        if 'pairEnrich' in res['data']['currentBackground']:\n",
    "            enrichment = res['data']['currentBackground']['pairEnrich']['nodes']\n",
    "        else: \n",
    "            enrichment = res['data']['currentBackground']['pairedEnrich']['nodes']\n",
    "        \n",
    "        df_enrichment_pair = pd.DataFrame(enrichment)\n",
    "\n",
    "        if df_enrichment_pair.empty:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        df_enrichment_pair[\"geneSetIdUp\"] = df_enrichment_pair[\"geneSet\"].map(\n",
    "            lambda t: next((node['id'] for node in t['nodes'] if ' up' in node['term']), None)\n",
    "        )\n",
    "\n",
    "        df_enrichment_pair[\"geneSetIdDown\"] = df_enrichment_pair[\"geneSet\"].map(\n",
    "            lambda t: next((node['id'] for node in t['nodes'] if ' down' in node['term']), None)\n",
    "        )\n",
    "        \n",
    "        df_enrichment_pair[\"term\"] = df_enrichment_pair[\"geneSet\"].map(\n",
    "            lambda t: t['nodes'][0]['term']\n",
    "        )\n",
    "        \n",
    "        def try_or_else_factory(fn, other):\n",
    "            def try_or_else(*args, **kwargs):\n",
    "                try: return fn(*args, **kwargs)\n",
    "                except: return other\n",
    "            return try_or_else\n",
    "        \n",
    "        df_enrichment_pair[\"approved\"] = df_enrichment_pair[\"geneSet\"].map(\n",
    "            try_or_else_factory(lambda t: t['nodes'][0]['geneSetFdaCountsById']['nodes'][0]['approved'], False)\n",
    "        )\n",
    "        \n",
    "        df_enrichment_pair[\"count\"] = df_enrichment_pair[\"geneSet\"].map(\n",
    "            try_or_else_factory(lambda t: t['nodes'][0]['geneSetFdaCountsById']['nodes'][0]['count'], 0)\n",
    "        )\n",
    "        \n",
    "        df_enrichment_pair = df_enrichment_pair.drop(columns=['geneSet']).reset_index(drop=True)\n",
    "        \n",
    "        return df_enrichment_pair\n",
    "\n",
    "    def get_overlap(self, genes, id, url=\"http://l2s2.maayanlab.cloud/graphql\"):\n",
    "        query = {\n",
    "        \"operationName\": \"OverlapQuery\",\n",
    "        \"variables\": {\n",
    "            \"id\": id,\n",
    "            \"genes\": genes\n",
    "        },\n",
    "        \"query\": \"\"\"query OverlapQuery($id: UUID!, $genes: [String]!) {geneSet(id: $id) {\n",
    "        overlap(genes: $genes) {\n",
    "        nodes {\n",
    "            symbol\n",
    "            ncbiGeneId\n",
    "            description\n",
    "            summary\n",
    "        }   }}}\"\"\"\n",
    "        }\n",
    "        \n",
    "        headers = {\n",
    "            \"Accept\": \"application/json\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "\n",
    "        response = requests.post(url, data=json.dumps(query), headers=headers)\n",
    "        \n",
    "        response.raise_for_status()\n",
    "        res = response.json()\n",
    "        return [item['symbol'] for item in res['data']['geneSet']['overlap']['nodes']]\n",
    "\n",
    "    def get_up_dn_overlap(self, genes_up: list[str], genes_down: list[str], id_up: str, id_down: str, overlap_type: str,  url=\"http://l2s2.maayanlab.cloud/graphql\"):\n",
    "        if overlap_type == 'mimickers':\n",
    "            up_up_overlap = self.get_overlap(genes_up, id_up, url)\n",
    "            dn_dn_overlap = self.get_overlap(genes_down, id_down, url)\n",
    "            return list(set(up_up_overlap) | set(dn_dn_overlap))\n",
    "        elif overlap_type == 'reversers':\n",
    "            up_dn_overlap = self.get_overlap(genes_up, id_down, url)\n",
    "            dn_up_overlap = self.get_overlap(genes_down, id_up, url)\n",
    "            return list(set(up_dn_overlap) | set(dn_up_overlap))\n",
    "        \n",
    "    def add_user_geneset(self, geneset, geneset_dn = None, url=\"http://l2s2.maayanlab.cloud/graphql\"):\n",
    "        query = {\n",
    "                \"query\": \"mutation AddUserGeneSet($genes: [String] = [\\\"AKT1\\\"], $description: String = \\\"\\\") {\\n  addUserGeneSet(input: {genes: $genes, description: $description}) {\\n    userGeneSet {\\n      id\\n    }\\n  }\\n}\",\n",
    "                \"variables\": {\n",
    "                    \"genes\": geneset,\n",
    "                    \"description\": \"User gene set\" if geneset_dn is not None else \"User gene set (up)\"\n",
    "                },\n",
    "                \"operationName\": \"AddUserGeneSet\"\n",
    "        }\n",
    "        \n",
    "        headers = {\n",
    "            \"Accept\": \"application/json\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "\n",
    "        response = requests.post(url, data=json.dumps(query), headers=headers)\n",
    "        \n",
    "        response.raise_for_status()\n",
    "        res = response.json()\n",
    "        \n",
    "        if geneset_dn is not None:\n",
    "            query = {\n",
    "                \"query\": \"mutation AddUserGeneSet($genes: [String] = [\\\"AKT1\\\"], $description: String = \\\"\\\") {\\n  addUserGeneSet(input: {genes: $genes, description: $description}) {\\n    userGeneSet {\\n      id\\n    }\\n  }\\n}\",\n",
    "                \"variables\": {\n",
    "                    \"genes\": geneset_dn,\n",
    "                    \"description\": \"User gene set (down)\"\n",
    "                },\n",
    "                \"operationName\": \"AddUserGeneSet\"\n",
    "            }\n",
    "            \n",
    "            response = requests.post(url, data=json.dumps(query), headers=headers)\n",
    "            \n",
    "            response.raise_for_status()\n",
    "            res_dn = response.json()\n",
    "            return res['data']['addUserGeneSet']['userGeneSet']['id'], res_dn['data']['addUserGeneSet']['userGeneSet']['id']\n",
    "        \n",
    "        return res['data']['addUserGeneSet']['userGeneSet']['id']\n",
    "\n",
    "    def get_l2s2_valid_genes(self, genes: list[str], url=\"http://l2s2.maayanlab.cloud/graphql\"):\n",
    "        query = {\n",
    "        \"query\": \"\"\"query GenesQuery($genes: [String]!) {\n",
    "            geneMap2(genes: $genes) {\n",
    "                nodes {\n",
    "                    gene\n",
    "                    geneInfo {\n",
    "                        symbol\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\"\"\",\n",
    "        \"variables\": {\"genes\": genes},\n",
    "        \"operationName\": \"GenesQuery\"\n",
    "        }\n",
    "        \n",
    "        headers = {\n",
    "            \"Accept\": \"application/json\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "\n",
    "        response = requests.post(url, data=json.dumps(query), headers=headers)\n",
    "\n",
    "        response.raise_for_status()\n",
    "        res = response.json()\n",
    "        return [g['geneInfo']['symbol'] for g in res['data']['geneMap2']['nodes'] if g['geneInfo'] != None]\n",
    "\n",
    "         \n",
    "    def display_table(self, db):\n",
    "        if db==\"l2s2_fda\":\n",
    "            approval = \"FDA-approved\"\n",
    "            library = \"LINCS L1000\"\n",
    "            df = self.l2s2_df\n",
    "            up_id = self.l2s2_geneset_up_id\n",
    "            down_id = self.l2s2_geneset_dn_id\n",
    "\n",
    "        elif db==\"l2s2_all\":\n",
    "            approval = \"\"\n",
    "            library = \"LINCS L1000\"\n",
    "            df = self.l2s2_df_nofda\n",
    "            up_id = self.l2s2_geneset_up_id\n",
    "            down_id = self.l2s2_geneset_dn_id\n",
    "\n",
    "        elif db==\"drugseqr_fda\":\n",
    "            approval = \"FDA-approved\"\n",
    "            library = \"DRUG-seq\"\n",
    "            df = self.drugseqr_df\n",
    "            up_id = self.drugseqr_geneset_up_id\n",
    "            down_id = self.drugseqr_geneset_dn_id\n",
    "\n",
    "        elif db==\"drugseqr_all\":\n",
    "            approval = \"\"\n",
    "            library = \"DRUG-seq\"\n",
    "            df = self.drugseqr_df_nofda\n",
    "            up_id = self.drugseqr_geneset_up_id\n",
    "            down_id = self.drugseqr_geneset_dn_id\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Choose a valid dataset.\")\n",
    "\n",
    "        termdict = {\n",
    "            \"mimickers\": \"mimic\",\n",
    "            \"reversers\": \"reverse\"\n",
    "        }\n",
    "\n",
    "        if df.empty:\n",
    "            raise ValueError(f\"No Results for {db}\")\n",
    "\n",
    "        df_t20 = df.iloc[:20]\n",
    "        \n",
    "        # print(df_t20.columns)\n",
    "        # print(df_t20.empty)\n",
    "        \n",
    "        columns = ['perturbation', 'term']\n",
    "        if self.direction == \"mimickers\":\n",
    "            columns.extend(['pvalueMimic', 'adjPvalueMimic', 'oddsRatioMimic', 'mimickerOverlap'])\n",
    "        else:\n",
    "            columns.extend(['pvalueReverse', 'adjPvalueReverse', 'oddsRatioReverse','reverserOverlap'])\n",
    "\n",
    "        columns.extend(['approved', 'count'])\n",
    "\n",
    "        display(df_t20[columns])\n",
    "\n",
    "        # display(df_t20)\n",
    "        \n",
    "        display(Markdown(f\"Table {self.tab_num}: Ranked {approval} {library} signatures predicted to {termdict[self.direction]} the uploaded geneset.\"))\n",
    "        display(HTML(f\"<a href=\\\"https://l2s2.maayanlab.cloud/enrichpair?dataset={up_id}&dataset={down_id}&fda=true&dir={self.direction_str.strip()}&sort={'pvalue_reverse' if self.direction_str == 'down' else 'pvalue_mimic'}\\\" target=\\\"_blank\\\">View in L2S2</a>\"))\n",
    "        self.tab_num += 1\n",
    "\n",
    "        filename = os.path.join(self.save_path, f\"{self.save_name}_{self.direction}_{db}.tsv\")\n",
    "        df[:200].to_csv(filename, sep='\\t')\n",
    "        display(FileLink(filename, result_html_prefix=\"Download table: \"))\n",
    "\n",
    "    def display_barplot(self, db, save_formats, color='tomato'): \n",
    "        if db == \"l2s2_fda\":\n",
    "            df = self.l2s2_df\n",
    "            approval = \"FDA-approved\"\n",
    "        elif db == \"l2s2_all\":\n",
    "            df = self.l2s2_df_nofda\n",
    "            approval = \"\"\n",
    "        elif db == \"drugseqr_fda\":\n",
    "            df = self.drugseqr_df\n",
    "            approval = \"FDA-approved\"\n",
    "        elif db == \"drugseqr_all\":\n",
    "            df = self.drugseqr_df_nofda\n",
    "            approval = \"\"\n",
    "        else:\n",
    "            raise ValueError(\"Choose a valid dataset.\")\n",
    "        \n",
    "        if df.empty:\n",
    "            raise ValueError(f\"No Results for {db}\")\n",
    "        df_t20 = df.iloc[:20]\n",
    "        bar_color_not_sig = \"lightgrey\"\n",
    "        bar_color = color\n",
    "        edgecolor=None\n",
    "\n",
    "        if self.direction == 'mimickers':\n",
    "            pvalcol = 'pvalueMimic'\n",
    "        else:\n",
    "            pvalcol = 'pvalueReverse'\n",
    "        \n",
    "\n",
    "        \n",
    "        df_t20['-log10(pvalue)'] = np.log10(df_t20[pvalcol])*-1\n",
    "        df_t20 = df_t20.groupby(by=\"perturbation\", level=None, sort=False).mean().reset_index()\n",
    "        df_t20.sort_values(by='-log10(pvalue)', ascending=True)\n",
    "        bar_colors = [bar_color if (x < 0.05) else bar_color_not_sig for x in df_t20[pvalcol].tolist()]\n",
    "        \n",
    "        fig=sns.barplot(\n",
    "            data=df_t20,\n",
    "            x=\"-log10(pvalue)\", \n",
    "            y=\"perturbation\",\n",
    "            palette=bar_colors,\n",
    "            legend=False,\n",
    "            edgecolor=edgecolor,\n",
    "            linewidth=1,\n",
    "            orient='y',\n",
    "            errorbar=None,\n",
    "            #ax=ax\n",
    "        )\n",
    "\n",
    "        fig.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        fig.tick_params(axis='x', which='major', labelsize=10)\n",
    "\n",
    "        fig.axes.get_yaxis().set_visible(False)\n",
    "        for i in range(len(df_t20)):\n",
    "            if df_t20[pvalcol].iloc[i] < 0.05:\n",
    "                annot = f\" *{df_t20['perturbation'].iloc[i]} {np.format_float_scientific(df_t20[pvalcol].iloc[i],precision=2)}\"\n",
    "            else:\n",
    "                annot = f\" {df_t20['perturbation'].iloc[i]} {np.format_float_scientific(df_t20[pvalcol].iloc[i],precision=2)}\"\n",
    "            \n",
    "            title_start= max(fig.axes.get_xlim())/200\n",
    "            fig.text(title_start,i,annot,ha='left', va='center', wrap = True, fontsize = 8)\n",
    "\n",
    "        for fmt in save_formats:\n",
    "            file_path = os.path.join(self.save_path, f\"{self.save_name}_{self.direction}_{db}.{fmt}\")\n",
    "            plt.savefig(file_path, bbox_inches=\"tight\", dpi=300)\n",
    "        \n",
    "        #plt.show()\n",
    "\n",
    "        display(Image(os.path.join(self.save_path, f\"{self.save_name}_{self.direction}_{db}.png\"), width=600))\n",
    "        display(Markdown(f\"Figure {self.fig_num}: barplot representation depicting the -log10p values of the top {approval} {db} {self.direction}. Red bars represent statistically significant results; otherwise gray.\"))\n",
    "        self.fig_num += 1\n",
    "\n",
    "        for fmt in save_formats:\n",
    "            file_path = os.path.join(self.save_path, f\"{self.save_name}_{self.direction}_{db}.{fmt}\")\n",
    "            display(FileLink(file_path, result_html_prefix=f\"Download bar plot as {fmt}\"))\n",
    "        \n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0e025b",
   "metadata": {},
   "source": [
    "### **Reverser Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc115f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs = ['l2s2_fda', 'l2s2_all', 'drugseqr_fda', 'drugseqr_all']\n",
    "\n",
    "for sig_name in sig_names_clean:\n",
    "    # up_genes_t500 = upreg_t500[sig_name]\n",
    "    # down_genes_t500 = downreg_t500[sig_name]\n",
    "    up_genes = upreg[sig_name]\n",
    "    down_genes = upreg[sig_name]\n",
    "    \n",
    "    rev_drugs = druganalysis(geneset=up_genes_t500, geneset_dn=down_genes_t500, direction=\"reversers\", save_path=resource_path, save_name=sig_name, tab_num=tab_num, fig_num=fig_num)\n",
    "    display(Markdown(f\"#### **{sig_name}**\"))\n",
    "    \n",
    "    for db in dbs:\n",
    "        display(Markdown(f\"**{db}**\"))\n",
    "        try:\n",
    "            rev_drugs.display_table(db=db)\n",
    "            rev_drugs.display_barplot(db=db, save_formats=save_formats)\n",
    "        except ValueError as e:\n",
    "            print(\"Caught error: \", e)\n",
    "\n",
    "    fig_num = rev_drugs.fig_num\n",
    "    tab_num  = rev_drugs.tab_num\n",
    "\n",
    "    display(Markdown(\"---\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b731ddd",
   "metadata": {},
   "source": [
    "#### **Mimicker Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179d6f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sig_name in sig_names_clean:\n",
    "    # up_genes_t500 = upreg_t500[sig_name]\n",
    "    # down_genes_t500 = downreg_t500[sig_name]\n",
    "\n",
    "    up_genes = upreg[sig_name]\n",
    "    down_genes = upreg[sig_name]\n",
    "\n",
    "    mim_drugs = druganalysis(geneset=up_genes_t500, geneset_dn=down_genes_t500, direction=\"mimickers\", save_path=resource_path, save_name=sig_name, tab_num=tab_num, fig_num=fig_num)\n",
    "    display(Markdown(f\"#### **{sig_name}**\"))\n",
    "    \n",
    "    for db in dbs:\n",
    "        display(Markdown(f\"\\n**{db}**\"))\n",
    "        try:\n",
    "            mim_drugs.display_table(db=db)\n",
    "            mim_drugs.display_barplot(db=db, save_formats=save_formats)\n",
    "        except ValueError as e:\n",
    "            print(\"Caught error: \", e)\n",
    "\n",
    "    fig_num = mim_drugs.fig_num\n",
    "    tab_num  = mim_drugs.tab_num\n",
    "\n",
    "    display(Markdown(\"---\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763ceac6",
   "metadata": {},
   "source": [
    "## **References**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c09889",
   "metadata": {},
   "outputs": [],
   "source": [
    "references = f'''\n",
    "[1] {citation}\n",
    "\n",
    "[2] McInnes L, Healy J, Saul N, Großberger L. UMAP: Uniform manifold approximation and projection. Journal of Open Source Software. 2018;3(29):861. doi:10.21105/joss.00861\n",
    "\n",
    "[3] Clark NR, Ma’ayan A. Introduction to statistical methods to analyze large data sets: Principal Components Analysis. Science Signaling. 2011;4(190):tr3-tr3. doi:10.1126/scisignal.2001967 \n",
    "\n",
    "[4] van der Maaten L, Hinton G. Visualizing Data using t-SNE. Journal of Machine Learning Research. 2008;9(86):2579-2605.\n",
    "\n",
    "[5] Chen EY, Tan CM, Kou Y, Duan Q, Wang Z, Meirelles GV, Clark NR, Ma'ayan A. Enrichr: interactive and collaborative HTML5 gene list enrichment analysis tool. BMC Bioinformatics. 2013;128(14)\n",
    "\n",
    "[6] Kuleshov MV, Jones MR, Rouillard AD, Fernandez NF, Duan Q, Wang Z, Koplev S, Jenkins SL, Jagodnik KM, Lachmann A, McDermott MG, Monteiro CD, Gundersen GW, Ma'ayan A. Enrichr: a comprehensive gene set enrichment analysis web server 2016 update. Nucleic Acids Research. 2016; gkw377.\n",
    "\n",
    "[7] Xie Z, Bailey A, Kuleshov MV, Clarke DJB., Evangelista JE, Jenkins SL, Lachmann A, Wojciechowicz ML, Kropiwnicki E, Jagodnik KM, Jeon M, & Ma’ayan A. Gene set knowledge discovery with Enrichr. Current Protocols, 1, e90. 2021. doi: 10.1002/cpz1.90\n",
    "\n",
    "[8] Keenan AB, Torre D, Lachmann A, Leong AK, Wojciechowicz M, Utti V, Jagodnik K, Kropiwnicki E, Wang Z, Ma'ayan A (2019) ChEA3: transcription factor enrichment analysis by orthogonal omics integration. Nucleic Acids Research. doi: 10.1093/nar/gkz446\n",
    "\n",
    "[9] Marino GB, Evangelista JE, Clarke DJB, Ma’ayan A. L2S2: chemical perturbation and CRISPR KO LINCS L1000 signature search engine. Nucleic Acids Res. 2025; gkaf373. doi:10.1093/nar/gkaf373\n",
    "\n",
    "[10] Li J, Ho DJ, Henault M, et al. DRUG-seq Provides Unbiased Biological Activity Readouts for Neuroscience Drug Discovery. ACS Chem Biol. 2022;17(6):1401-1414. doi:10.1021/acschembio.1c00920\n",
    "\n",
    "[11] Lachmann A, Torre D, Keenan AB, Jagodnik KM, Lee HJ, Wang L, Silverstein MC, Ma'ayan A. Massive mining of publicly available RNA-seq data from human and mouse. Nature Communications 9. Article number: 1366 (2018), doi: 10.1038/s41467-018-03751-6.\n",
    "\n",
    "[12] Bray, N., Pimentel, H., Melsted, P. et al. Near-optimal probabilistic RNA-seq quantification. Nat Biotechnol 34, 525–527 (2016). https://doi.org/10.1038/nbt.3519\n",
    "\n",
    "[13] Fernandez, N. F. et al. Clustergrammer, a web-based heatmap visualization and analysis tool for high-dimensional biological data. Sci. Data 4:170151 doi: 10.1038/sdata.2017.151 (2017).\n",
    "\n",
    "[14] Ritchie ME, Phipson B, Wu D, Hu Y, Law CW, Shi W, Smyth GK. limma powers differential expression analyses for RNA-sequencing and microarray studies. Nucleic Acids Res. 2015 Apr 20;43(7):e47. doi: 10.1093/nar/gkv007.\n",
    "\n",
    "[15] Milacic M, Beavers D, Conley P, Gong C, Gillespie M, Griss J, Haw R, Jassal B, Matthews L, May B, Petryszak R, Ragueneau E, Rothfels K, Sevilla C, Shamovsky V, Stephan R, Tiwari K, Varusai T, Weiser J, Wright A, Wu G, Stein L, Hermjakob H, D’Eustachio P. The Reactome Pathway Knowledgebase 2024. Nucleic Acids Research. 2024. doi: 10.1093/nar/gkad1025.\n",
    "\n",
    "[16] Eppig JT, Smith CL, Blake JA, Ringwald M, Kadin JA, Richardson JE, Bult CJ. Mouse Genome Informatics (MGI): Resources for Mining Mouse Genetic, Genomic, and Biological Data in Support of Primary and Translational Research. Methods Mol Biol. 2017;1488:47-73. doi: 10.1007/978-1-4939-6427-7_3.\n",
    "\n",
    "[17] Ashburner M, Ball CA, Blake JA, Botstein D, Butler H, Cherry JM, Davis AP, Dolinski K, Dwight SS, Eppig JT, Harris MA, Hill DP, Issel-Tarver L, Kasarskis A, Lewis S, Matese JC, Richardson JE, Ringwald M, Rubin GM, Sherlock G. Gene ontology: tool for the unification of biology. The Gene Ontology Consortium. Nat Genet. 2000 May;25(1):25-9. doi: 10.1038/75556.\n",
    "\n",
    "[18] Cerezo M, Sollis E, Ji Y, et al. The NHGRI-EBI GWAS Catalog: standards for reusability, sustainability and diversity. Nucleic Acids Res. 2025;53(D1):D998-D1005. doi:10.1093/nar/gkae1070\n",
    "\n",
    "[19] Kanehisa M, Furumichi M, Sato Y, Matsuura Y, Ishiguro-Watanabe M. KEGG: biological systems database as a model of the real world. Nucleic Acids Res. 2025;53(D1):D672-D677. doi:10.1093/nar/gkae909\n",
    "\n",
    "[20] Kanehisa M, Goto S. KEGG: kyoto encyclopedia of genes and genomes. Nucleic Acids Res. 2000;28(1):27-30. doi:10.1093/nar/28.1.27\n",
    "\n",
    "[21] Kanehisa M. Toward understanding the origin and evolution of cellular organisms. Protein Sci. 2019;28(11):1947-1951. doi:10.1002/pro.3715\n",
    "\n",
    "[22] Pico AR, Kelder T, van Iersel MP, Hanspers K, Conklin BR, Evelo C. WikiPathways: pathway editing for the people. PLoS Biol. 2008 Jul 22;6(7):e184. doi: 10.1371/journal.pbio.0060184.\n",
    "\n",
    "[23] GTEx Consortium. The Genotype-Tissue Expression (GTEx) project. Nat Genet. 2013 Jun;45(6):580-5. doi: 10.1038/ng.2653.\n",
    "\n",
    "[24] ENCODE Project Consortium. An integrated encyclopedia of DNA elements in the human genome. Nature. 2012;489(7414):57-74. doi:10.1038/nature11247\n",
    "\n",
    "[25] Luo Y, Hitz BC, Gabdank I, et al. New developments on the Encyclopedia of DNA Elements (ENCODE) data portal. Nucleic Acids Res. 2020;48(D1):D882-D889. doi:10.1093/nar/gkz1062\n",
    "\n",
    "[26] Hammal F, de Langen P, Bergon A, Lopez F, Ballester B. ReMap 2022: a database of Human, Mouse, Drosophila and Arabidopsis regulatory regions from an integrative analysis of DNA-binding sequencing experiments. Nucleic Acids Res. 2022;50(D1):D316-D325. doi:10.1093/nar/gkab996\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3dfa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(references))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
